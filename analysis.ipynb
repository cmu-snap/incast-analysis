{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6565c4f-07a2-4ae2-8b73-da294753b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915fdcb-ffa2-4dc1-83d0-df65b094043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"/data_hdd/incast/out/15ms-200-3-TcpDctcp-10icwnd-0offset-none-rwnd1000000B-20tokens-4g-80ecn-2_2da\"\n",
    "OUT_DIR_GRAPHS = path.join(OUT_DIR, \"graphs\")\n",
    "if not path.isdir(OUT_DIR_GRAPHS):\n",
    "    os.makedirs(OUT_DIR_GRAPHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d03cb-7e6d-4a8a-a28a-c39e3b2fc772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Add burstiness analysis from receiver pcap, flow level\n",
    "\n",
    "\n",
    "def filter_samples(samples, start, end):\n",
    "    return [sample for sample in samples if start <= sample[0] <= end]\n",
    "\n",
    "\n",
    "def separate_samples_into_bursts(\n",
    "    samples,\n",
    "    burst_times,\n",
    "    flow_times=None,\n",
    "    filter_on_flow_times=False,\n",
    "    bookend=True,\n",
    "    earliest_sec=None,\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    bursts = []\n",
    "\n",
    "    if filter_on_flow_times:\n",
    "        assert flow_times is not None\n",
    "    else:\n",
    "        assert flow_times is None\n",
    "        flow_times = [(None, None, None, None)] * num_bursts\n",
    "\n",
    "    for burst_idx, (\n",
    "        (burst_start, burst_end),\n",
    "        (flow_start, _, flow_end, _),\n",
    "    ) in enumerate(zip(burst_times, flow_times)):\n",
    "        burst = []\n",
    "        for sample in samples:\n",
    "            if burst_start <= sample[0] <= burst_end and (\n",
    "                not filter_on_flow_times or flow_start <= sample[0] <= flow_end\n",
    "            ):\n",
    "                # This sample is part of the current burst.\n",
    "                burst.append(sample)\n",
    "\n",
    "        # Insert a sample at precisely the start and end time for this burst, if possible.\n",
    "        if bookend:\n",
    "            start, end = (\n",
    "                (flow_start, flow_end)\n",
    "                if filter_on_flow_times\n",
    "                else (burst_start, burst_end)\n",
    "            )\n",
    "            if burst_idx > 0:\n",
    "                # Make sure that the burst has a sample at the start time\n",
    "                # Two case: Either we have no samples for this burst, so we take\n",
    "                # the last value from the previous burst, or we do have samples for\n",
    "                # this burst but not at the start time, so we also take the last\n",
    "                # value from the previous burst. In both cases, make sure there is\n",
    "                # a previous burst.\n",
    "                if (not burst and bursts[-1]) or (\n",
    "                    burst and burst[0][0] != start and bursts[-1]\n",
    "                ):\n",
    "                    burst.insert(0, (start, *bursts[-1][-1][1:]))\n",
    "            # Every burst should now have at least one sample: start.\n",
    "            # Note: This will fail if we have no data for the first burst.\n",
    "\n",
    "            if burst:\n",
    "                # Make sure that the burst has a sample at the end time\n",
    "                if burst[-1][0] != end:\n",
    "                    burst.append((end, *burst[-1][1:]))\n",
    "                # Every burst should now have at least two samples: start and end\n",
    "                assert len(burst) >= 2, (burst, start, end)\n",
    "\n",
    "        bursts.append(burst)\n",
    "    # Make sure we have the expected number of bursts\n",
    "    assert len(bursts) == num_bursts\n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b4080-3a1c-41de-9746-eab4f6e099cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_times_line(line):\n",
    "    # Format: <start time seconds> <end time seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    return [float(sec) for sec in parts]\n",
    "\n",
    "\n",
    "def parse_burst_times(out_dir):\n",
    "    with open(\n",
    "        path.join(out_dir, \"logs\", \"burst_times.log\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        return [parse_times_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def parse_config_json(out_dir):\n",
    "    with open(path.join(out_dir, \"config.json\"), \"r\", encoding=\"utf-8\") as fil:\n",
    "        return json.load(fil)\n",
    "\n",
    "\n",
    "BURST_TIMES = parse_burst_times(OUT_DIR)\n",
    "# BURST_TIMES = [(start, (start + 0.03) if (end - start) > 0.03 else end) for start, end in BURST_TIMES]\n",
    "\n",
    "CONFIG = parse_config_json(OUT_DIR)\n",
    "\n",
    "ideal_sec = CONFIG[\"bytesPerSender\"] * CONFIG[\"numSenders\"] / (\n",
    "    CONFIG[\"smallLinkBandwidthMbps\"] * 1e6 / 8\n",
    ") + (6 * CONFIG[\"delayPerLinkUs\"] / 1e6)\n",
    "print(\n",
    "    \"Burst times:\",\n",
    "    f\"Ideal: {ideal_sec * 1e3:.4f} ms\",\n",
    "    *[\n",
    "        f\"{burst_idx + 1}: [{start} -> {end}] - {(end - start) * 1e3:.4f} ms - {(end - start) / ideal_sec * 100:.2f} %\"\n",
    "        for burst_idx, (start, end) in enumerate(BURST_TIMES)\n",
    "    ],\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "MARKING_THRESHOLD = CONFIG[\"smallQueueMinThresholdPackets\"]\n",
    "QUEUE_CAPACITY = CONFIG[\"smallQueueSizePackets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d95142-2dd1-482d-bdbd-08bb940ff90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_queue_line(line):\n",
    "    # Format: <timestamp seconds> <num packets> <backlog time microseconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, packets = parts\n",
    "    time_sec = float(time_sec)\n",
    "    packets = int(packets)\n",
    "    # backlog_us = float(backlog_us)\n",
    "    return time_sec, packets  # , backlog_us\n",
    "\n",
    "\n",
    "def parse_mark_line(line):\n",
    "    # Format <timestamp seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 1\n",
    "    return (float(parts[0]), None)\n",
    "\n",
    "\n",
    "def parse_drop_line(line):\n",
    "    # Format: <timestamp seconds> <drop type>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, drop_type = parts\n",
    "    time_sec = float(time_sec)\n",
    "    drop_type = int(drop_type)\n",
    "    return time_sec, drop_type\n",
    "\n",
    "\n",
    "def graph_queue(\n",
    "    out_dir, queue_name, burst_times, marking_threshold_packets, capacity_packets\n",
    "):\n",
    "    queue_prefix = (\n",
    "        \"incast_queue\"\n",
    "        if queue_name == \"Incast Queue\"\n",
    "        else (\"uplink_queue\" if queue_name == \"Uplink Queue\" else None)\n",
    "    )\n",
    "    assert queue_prefix is not None\n",
    "    depth_flp = path.join(out_dir, f\"{queue_prefix}_depth.log\")\n",
    "    mark_flp = path.join(out_dir, f\"{queue_prefix}_mark.log\")\n",
    "    drop_flp = path.join(out_dir, f\"{queue_prefix}_drop.log\")\n",
    "\n",
    "    depth_samples = []\n",
    "    with open(depth_flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        depth_samples = [\n",
    "            parse_queue_line(line) for line in fil if line.strip()[0] != \"#\"\n",
    "        ]\n",
    "    burst_depths = separate_samples_into_bursts(depth_samples, burst_times)\n",
    "\n",
    "    mark_samples = []\n",
    "    with open(mark_flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        mark_samples = [parse_mark_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    burst_marks = separate_samples_into_bursts(mark_samples, burst_times, bookend=False)\n",
    "\n",
    "    drop_samples = []\n",
    "    with open(drop_flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        drop_samples = [parse_drop_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    burst_drops = separate_samples_into_bursts(drop_samples, burst_times, bookend=False)\n",
    "\n",
    "    num_bursts = len(burst_depths)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, (ax, burst) in enumerate(zip(axes, burst_depths)):\n",
    "        # Plot marks and drops on a second y axis\n",
    "\n",
    "        # If there are marks, plot them...\n",
    "        if burst_idx < len(burst_marks) and burst_marks[burst_idx]:\n",
    "            mark_xs, _ = zip(*burst_marks[burst_idx])\n",
    "            mark_ys = [marking_threshold_packets] * len(mark_xs)\n",
    "            ax.plot(mark_xs, mark_ys, \"x\", color=\"orange\", label=\"ECN marks\", alpha=0.8)\n",
    "\n",
    "        # If there are drops, plot them...\n",
    "        if burst_idx < len(burst_drops) and burst_drops[burst_idx]:\n",
    "            drop_xs, _ = zip(*burst_drops[burst_idx])\n",
    "            drop_ys = [capacity_packets] * len(drop_xs)\n",
    "            ax.plot(drop_xs, drop_ys, \"x\", color=\"red\", label=\"Drops\", alpha=0.8)\n",
    "\n",
    "        # Plot depth\n",
    "        xs, ys = zip(*burst)\n",
    "        blue = \"tab:blue\"\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", color=blue, alpha=0.8)\n",
    "\n",
    "        # Draw a line at the marking threshold\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [marking_threshold_packets] * 2,\n",
    "            label=\"Marking threshold\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        # Draw a line at the queue capacity\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [capacity_packets] * 2,\n",
    "            label=\"Queue capacity\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"dotted\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{queue_name} Length: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"queue length (packets)\")\n",
    "        # ax.tick_params(axis='y', labelcolor=blue)\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS,\n",
    "        path.basename(OUT_DIR) + \"_\" + \"_\".join(queue_name.split(\" \")).lower(),\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "    return burst_depths, burst_marks, burst_drops\n",
    "\n",
    "\n",
    "INCAST_Q_DEPTHS_BY_BURST, _, _ = graph_queue(\n",
    "    path.join(OUT_DIR, \"logs\"),\n",
    "    \"Incast Queue\",\n",
    "    BURST_TIMES,\n",
    "    MARKING_THRESHOLD,\n",
    "    QUEUE_CAPACITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693eb0f-154e-4219-9602-4d14dc7c1928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_time_at_or_above_threshold_helper(depths, thresh, start_sec, end_sec):\n",
    "    # Identify crossover points and above regions points by filtering burst_samples.\n",
    "    above_regions = []\n",
    "    last_depth = None\n",
    "    last_cross_up = None\n",
    "    for x, depth in depths:\n",
    "        if depth < thresh:\n",
    "            if last_cross_up is not None:\n",
    "                above_regions.append((last_cross_up, x))\n",
    "                last_cross_up = None\n",
    "        elif depth >= thresh:\n",
    "            if last_depth is None or last_depth < thresh:\n",
    "                last_cross_up = x\n",
    "        last_depth = depth\n",
    "    if last_cross_up is not None:\n",
    "        above_regions.append((last_cross_up, end_sec))\n",
    "\n",
    "    above_sec = sum(\n",
    "        region_end_sec - region_start_sec\n",
    "        for region_start_sec, region_end_sec in above_regions\n",
    "    )\n",
    "    total_sec = end_sec - start_sec\n",
    "    return above_sec, total_sec, above_sec / total_sec * 100\n",
    "\n",
    "\n",
    "def calculate_time_at_or_above_threshold(burst_depths, burst_times, thresh, label):\n",
    "    num_bursts = len(burst_times)\n",
    "    for burst_idx, (depths, (start_sec, end_sec)) in enumerate(\n",
    "        zip(burst_depths, burst_times)\n",
    "    ):\n",
    "        above_sec, total_sec, perc = calculate_time_at_or_above_threshold_helper(\n",
    "            depths, thresh, start_sec, end_sec\n",
    "        )\n",
    "        print(\n",
    "            f\"Burst {burst_idx + 1} of {num_bursts} - Time above {label}: {above_sec * 1e3:.2f} ms ({perc:.2f}%)\"\n",
    "        )\n",
    "\n",
    "\n",
    "calculate_time_at_or_above_threshold(\n",
    "    INCAST_Q_DEPTHS_BY_BURST, BURST_TIMES, MARKING_THRESHOLD, \"marking threshold\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0ea62-e968-44c0-8775-033b81ddae7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_time_at_or_above_threshold(INCAST_Q_DEPTHS_BY_BURST, BURST_TIMES, 1, \"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a77e5-9719-4168-beb2-5c8b61be1ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_time_at_or_above_threshold(\n",
    "    INCAST_Q_DEPTHS_BY_BURST, BURST_TIMES, QUEUE_CAPACITY * 0.9, \"90% capacity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce597b6e-74ef-4963-9935-39603d0e34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _ = graph_queue(\n",
    "    path.join(OUT_DIR, \"logs\"),\n",
    "    \"Uplink Queue\",\n",
    "    BURST_TIMES,\n",
    "    MARKING_THRESHOLD,\n",
    "    QUEUE_CAPACITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be6075-4fbc-4b8a-88a0-d122b3db0d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_flow_times(flow_times_json):\n",
    "    return [\n",
    "        {\n",
    "            times[\"id\"]: (times[\"start\"], times[\"firstPacket\"], times[\"end\"], ip)\n",
    "            for ip, times in flows.items()\n",
    "        }\n",
    "        for burst, flows in sorted(flow_times_json.items(), key=lambda p: int(p[0]))\n",
    "    ]\n",
    "\n",
    "\n",
    "def graph_active_connections(log_dir, burst_times):\n",
    "    with open(path.join(log_dir, \"flow_times.json\"), \"r\", encoding=\"utf-8\") as fil:\n",
    "        flow_times = json.load(fil)\n",
    "    flow_times = parse_flow_times(flow_times)\n",
    "\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        times = flow_times[burst_idx].values()\n",
    "        starts, _, ends, _ = zip(*times)\n",
    "        serialized = [(start, 1) for start in starts] + [(end, -1) for end in ends]\n",
    "        serialized = sorted(serialized, key=lambda p: p[0])\n",
    "        # earliest_time = serialized[0][0]\n",
    "        # serialized = [(x - earliest_time, y) for x, y in serialized]\n",
    "        active = [serialized[0]]\n",
    "        for time, action in serialized[1:]:\n",
    "            active.append((time, active[-1][1] + action))\n",
    "        xs, ys = zip(*active)\n",
    "\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Active connections over time: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"active connections\")\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"active_connections\"\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "    return flow_times\n",
    "\n",
    "\n",
    "FLOW_TIMES = graph_active_connections(path.join(OUT_DIR, \"logs\"), BURST_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e9b9c-411e-4461-9869-5d3671dda229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_cdf_of_flow_duration(flow_times, burst_times):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(5, 3 * num_bursts), nrows=num_bursts, ncols=1)\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        times = flow_times[burst_idx].values()\n",
    "        durations = [end - start for start, _, end, _ in times]\n",
    "\n",
    "        count, bins_count = np.histogram(durations, bins=len(durations))\n",
    "        ax.plot(bins_count[1:], np.cumsum(count / sum(count)), alpha=0.8)\n",
    "\n",
    "        ax.set_title(f\"CDF of flow duration: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"duration (seconds)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"flow_duration_cdf\"\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "graph_cdf_of_flow_duration(FLOW_TIMES, BURST_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491fc08-1963-4a89-a561-3fdc27561b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_cwnd_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, cwnd_bytes = parts\n",
    "    time_sec = float(time_sec)\n",
    "    cwnd_bytes = int(cwnd_bytes)\n",
    "    return time_sec, cwnd_bytes\n",
    "\n",
    "\n",
    "def parse_cwnds(flp):\n",
    "    with open(flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        return [parse_cwnd_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def parse_sender(flp):\n",
    "    return int(path.basename(flp).split(\"_\")[0][6:])\n",
    "\n",
    "\n",
    "def graph_sender_cwnd(out_dir, burst_times, flow_times):\n",
    "    cwnd_flps = [\n",
    "        path.join(out_dir, fln)\n",
    "        for fln in os.listdir(out_dir)\n",
    "        if fln.startswith(\"sender\") and fln.endswith(\"_cwnd.log\")\n",
    "    ]\n",
    "\n",
    "    sender_to_cwnds_by_burst = {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all CWND samples for this sender\n",
    "            parse_cwnds(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            [burst_flow_times[parse_sender(flp)] for burst_flow_times in flow_times],\n",
    "            filter_on_flow_times=True,\n",
    "            earliest_sec=False,\n",
    "            bookend=True,\n",
    "        )\n",
    "        for flp in cwnd_flps\n",
    "    }\n",
    "\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            f\"CWND of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"CWND (bytes)\")\n",
    "\n",
    "        for sender, bursts in sender_to_cwnds_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(xs, ys, label=sender, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"cwnd\")\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "    return sender_to_cwnds_by_burst\n",
    "\n",
    "\n",
    "SENDER_TO_CWNDS_BY_BURST = graph_sender_cwnd(\n",
    "    path.join(OUT_DIR, \"logs\"), BURST_TIMES, FLOW_TIMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d4e81-9f1e-41a6-bf4f-2f2fb660a178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspired by https://stackoverflow.com/questions/10058227/calculating-mean-of-arrays-with-different-lengths\n",
    "def tolerant_metrics(xs, arrays, interp_delta, percentiles):\n",
    "    # Map x value to index. Used to quickly determine where each array starts\n",
    "    # relative to the overall xs.\n",
    "    xs_map = {\n",
    "        round(x, int(math.log(interp_delta, 10))): idx for idx, x in enumerate(xs)\n",
    "    }\n",
    "\n",
    "    # Create 2d array to fit the largest array\n",
    "    combined_2d = np.ma.empty((len(xs), len(arrays)))\n",
    "    combined_2d.mask = True\n",
    "\n",
    "    for idx, array in enumerate(arrays):\n",
    "        # Look up this array's start position\n",
    "        start_idx = xs_map[round(array[0][0], int(math.log(interp_delta, 10)))]\n",
    "        combined_2d[start_idx : start_idx + len(array), idx] = list(zip(*array))[1]\n",
    "\n",
    "    return (\n",
    "        combined_2d.mean(axis=-1),\n",
    "        combined_2d.std(axis=-1),\n",
    "        combined_2d.min(axis=-1),\n",
    "        combined_2d.max(axis=-1),\n",
    "        np.nanpercentile(\n",
    "            np.ma.filled(np.ma.masked_where(combined_2d < 0, combined_2d), np.nan),\n",
    "            percentiles,\n",
    "            axis=-1,\n",
    "        ),\n",
    "        combined_2d.sum(axis=-1),\n",
    "    )\n",
    "\n",
    "\n",
    "def step_interp(old_xs, old_ys, new_xs):\n",
    "    # Lengths must be nonzero and agree.\n",
    "    assert len(old_xs) > 0\n",
    "    assert len(old_ys) > 0\n",
    "    assert len(new_xs) > 0\n",
    "    assert len(old_xs) == len(old_ys)\n",
    "    # xs must be strictly non-decreasing.\n",
    "    assert (np.diff(old_xs) >= 0).all(), np.diff(old_xs)\n",
    "    assert (np.diff(new_xs) >= 0).all()\n",
    "    # This is strictly interpolation, not extrapolation.\n",
    "    assert new_xs[0] >= old_xs[0]\n",
    "    assert new_xs[-1] <= old_xs[-1]\n",
    "\n",
    "    new_ys = np.empty(len(new_xs))\n",
    "    # Points to the next value in xs and ys that is past the current x we are interpolating.\n",
    "    old_idx = 0\n",
    "    for new_idx, new_x in enumerate(new_xs):\n",
    "        # Move old_idx forward until it is at a position where the next element\n",
    "        # in old_xs is strictly greater than new_x.\n",
    "        #\n",
    "        # old_idx will never grow larger than len(old_xs) - 2\n",
    "        while old_idx < len(old_xs) - 2 and new_x >= old_xs[old_idx + 1]:\n",
    "            old_idx += 1\n",
    "\n",
    "        # If old_idx is immediately before the last element in old_xs, then\n",
    "        # check manually if we need to advance old_idx to the last element in\n",
    "        # old_xs.\n",
    "        if old_idx == len(old_xs) - 2:\n",
    "            if new_x >= old_xs[len(old_xs) - 1]:\n",
    "                old_idx += 1\n",
    "\n",
    "        new_ys[new_idx] = old_ys[old_idx]\n",
    "\n",
    "    assert len(new_xs) == len(new_ys)\n",
    "    return new_ys\n",
    "\n",
    "\n",
    "def interpolate_flows_for_burst(\n",
    "    sender_to_cwnds_by_burst, sender_to_cwnds_by_burst_interp, burst_idx, interp_delta\n",
    "):\n",
    "    # Interpolate each flow at uniform intervals.\n",
    "    for sender, bursts in sender_to_cwnds_by_burst.items():\n",
    "        if bursts[burst_idx]:\n",
    "            start_x = bursts[burst_idx][0][0]\n",
    "            end_x = bursts[burst_idx][-1][0]\n",
    "            new_xs = np.array(\n",
    "                [\n",
    "                    x / interp_delta\n",
    "                    for x in range(\n",
    "                        math.ceil(start_x * interp_delta),\n",
    "                        math.floor(end_x * interp_delta) + 1,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            assert len(bursts[burst_idx]) > 0\n",
    "            # print(\"interp_delta\", interp_delta)\n",
    "            # print(\"start_x\", start_x)\n",
    "            # print(\"end_x\", end_x)\n",
    "            # print(\n",
    "            #     \"math.ceil(start_x * interp_delta)\", math.ceil(start_x * interp_delta)\n",
    "            # )\n",
    "            # print(\n",
    "            #     \"math.floor(end_x * interp_delta) + 1\",\n",
    "            #     math.floor(end_x * interp_delta) + 1,\n",
    "            # )\n",
    "            assert len(new_xs) > 0\n",
    "            new_ys = step_interp(*zip(*bursts[burst_idx]), new_xs)\n",
    "        else:\n",
    "            new_xs = np.array([])\n",
    "            new_ys = np.array([])\n",
    "        sender_to_cwnds_by_burst_interp[sender].append(list(zip(new_xs, new_ys)))\n",
    "\n",
    "\n",
    "def calculate_aggregate_metrics(valid, interp_delta, percentiles):\n",
    "    # Determine the overall x-axis range for this burst, across all valid senders.\n",
    "    start_x = min(samples[0][0] for samples in valid)\n",
    "    end_x = max(samples[-1][0] for samples in valid)\n",
    "    xs = np.array(\n",
    "        [\n",
    "            x / interp_delta\n",
    "            for x in range(\n",
    "                math.floor(start_x * interp_delta), math.ceil(end_x * interp_delta) + 1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate and verify metrics.\n",
    "    avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys = tolerant_metrics(\n",
    "        xs, valid, interp_delta, percentiles\n",
    "    )\n",
    "    assert len(xs) == len(avg_ys)\n",
    "    assert len(xs) == len(stdev_ys)\n",
    "    assert len(xs) == len(min_ys)\n",
    "    assert len(xs) == len(max_ys)\n",
    "    assert len(xs) == percentiles_ys.shape[1]\n",
    "    assert len(xs) == len(sum_ys)\n",
    "\n",
    "    return xs, avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys\n",
    "\n",
    "\n",
    "def graph_aggregate_cwnd_per_burst_helper(\n",
    "    ax,\n",
    "    sender_to_cwnds_by_burst,\n",
    "    sender_to_cwnds_by_burst_interp,\n",
    "    burst_idx,\n",
    "    burst_times,\n",
    "    interp_delta,\n",
    "    percentiles,\n",
    "):\n",
    "    interpolate_flows_for_burst(\n",
    "        sender_to_cwnds_by_burst,\n",
    "        sender_to_cwnds_by_burst_interp,\n",
    "        burst_idx,\n",
    "        interp_delta,\n",
    "    )\n",
    "\n",
    "    # Throw away senders that do not have any samples for this burst.\n",
    "    valid = [\n",
    "        bursts[burst_idx]\n",
    "        for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "        if bursts[burst_idx]\n",
    "    ]\n",
    "    print(\n",
    "        f\"Burst {burst_idx} has \"\n",
    "        f\"{len(valid)}/{len(sender_to_cwnds_by_burst_interp)} \"\n",
    "        \"senders with at least one CWND sample.\"\n",
    "    )\n",
    "\n",
    "    (\n",
    "        xs,\n",
    "        avg_ys,\n",
    "        stdev_ys,\n",
    "        min_ys,\n",
    "        max_ys,\n",
    "        percentiles_ys,\n",
    "        _,\n",
    "    ) = calculate_aggregate_metrics(valid, interp_delta, percentiles)\n",
    "\n",
    "    # Left graph\n",
    "    ax[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "    ax[0].fill_between(\n",
    "        xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "    )\n",
    "    ax[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    ax[0].set_title(\n",
    "        f\"CWND of active connections: Burst {burst_idx + 1} of {len(burst_times)}\"\n",
    "    )\n",
    "    ax[0].set_xlabel(\"time (seconds)\")\n",
    "    ax[0].set_ylabel(\"CWND (bytes)\")\n",
    "    ax[0].set_ylim(bottom=0)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Right graph\n",
    "    ax[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    for idx in range(1, percentiles_ys.shape[0]):\n",
    "        ax[1].fill_between(\n",
    "            xs,\n",
    "            percentiles_ys[idx - 1],\n",
    "            percentiles_ys[idx],\n",
    "            alpha=0.5,\n",
    "            label=f\"p{percentiles[idx]}\",\n",
    "        )\n",
    "    ax[1].set_title(\n",
    "        f\"CWND of active connections: Burst {burst_idx + 1} of {len(burst_times)}\"\n",
    "    )\n",
    "    ax[1].set_xlabel(\"time (seconds)\")\n",
    "    ax[1].set_ylabel(\"CWND (bytes)\")\n",
    "    ax[1].set_ylim(bottom=0)\n",
    "    ax[1].legend()\n",
    "\n",
    "\n",
    "def graph_aggregate_cwnd_per_burst(\n",
    "    sender_to_cwnds_by_burst, burst_times, interp_delta, percentiles\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(13, 3 * num_bursts), nrows=num_bursts, ncols=2\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Calculate aggregate metrics, graph them, and store interpolated flows in\n",
    "    # this dict.\n",
    "    sender_to_cwnds_by_burst_interp = collections.defaultdict(list)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        graph_aggregate_cwnd_per_burst_helper(\n",
    "            ax,\n",
    "            sender_to_cwnds_by_burst,\n",
    "            sender_to_cwnds_by_burst_interp,\n",
    "            burst_idx,\n",
    "            burst_times,\n",
    "            interp_delta,\n",
    "            percentiles,\n",
    "        )\n",
    "\n",
    "    for sender, bursts_interp in sender_to_cwnds_by_burst_interp.items():\n",
    "        assert len(bursts_interp) == num_bursts\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"cwnd_analysis\")\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "    return sender_to_cwnds_by_burst_interp\n",
    "\n",
    "\n",
    "INTERP_DELTA = 1e5\n",
    "PERCENTILES = [0, 25, 50, 75, 95, 100]\n",
    "SENDER_TO_CWNDS_BY_BURST_INTERP = graph_aggregate_cwnd_per_burst(\n",
    "    SENDER_TO_CWNDS_BY_BURST, BURST_TIMES, INTERP_DELTA, PERCENTILES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19dd8b-4419-42fd-8d99-e372161a95c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_average_queue_depth(burst_depths, interp_delta, bandwidth_bps):\n",
    "    num_bursts = len(burst_depths)\n",
    "    for burst_idx, depths in enumerate(burst_depths):\n",
    "        old_xs, old_ys = zip(*depths)\n",
    "        start_x = old_xs[0]\n",
    "        end_x = old_xs[-1]\n",
    "        new_xs = np.array(\n",
    "            [\n",
    "                x / interp_delta\n",
    "                for x in range(\n",
    "                    math.ceil(start_x * interp_delta),\n",
    "                    math.floor(end_x * interp_delta) + 1,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        new_ys = step_interp(old_xs, old_ys, new_xs)\n",
    "        avg_q_packets = new_ys.mean()\n",
    "        avg_q_bytes = avg_q_packets * BYTES_PER_PACKET\n",
    "        avg_q_us = avg_q_bytes / (bandwidth_bps / 8) * 1e6\n",
    "        print(\n",
    "            f\"Burst {burst_idx + 1} of {num_bursts} - Average queue depth: {avg_q_packets:.2f} packets, {avg_q_bytes:.2f} bytes, {avg_q_us:.2f} us\"\n",
    "        )\n",
    "\n",
    "\n",
    "BYTES_PER_PACKET = 1500\n",
    "BANDWIDTH_BITSPS = CONFIG[\"smallLinkBandwidthMbps\"] * 1e6\n",
    "calculate_average_queue_depth(\n",
    "    INCAST_Q_DEPTHS_BY_BURST,\n",
    "    INTERP_DELTA,\n",
    "    BANDWIDTH_BITSPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2817c7b-0ee0-4ce1-9282-dd6c1b300342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_estimated_queue_ingress_rate(burst_depths, bandwidth_bps, interp_delta):\n",
    "    num_bursts = len(burst_depths)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, (ax, depths) in enumerate(zip(axes, burst_depths)):\n",
    "        old_xs, old_ys = zip(*depths)\n",
    "        start_x = old_xs[0]\n",
    "        end_x = old_xs[-1]\n",
    "        new_xs = np.array(\n",
    "            [\n",
    "                x / interp_delta\n",
    "                for x in range(\n",
    "                    math.ceil(start_x * interp_delta),\n",
    "                    math.floor(end_x * interp_delta) + 1,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        new_ys = step_interp(old_xs, old_ys, new_xs)\n",
    "        new_ys *= 8 * 1500\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Estimated queue ingress rate: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"ingress rate (Gbps)\")\n",
    "\n",
    "        dydxs = np.gradient(new_ys, new_xs)\n",
    "\n",
    "        # print(bandwidth_bps)\n",
    "        dydxs = np.array(\n",
    "            [\n",
    "                dydx if y == 0 else (dydx + bandwidth_bps)\n",
    "                for dydx, y in zip(dydxs, new_ys)\n",
    "            ]\n",
    "        )\n",
    "        dydxs /= 1e9\n",
    "\n",
    "        ax.plot(new_xs, dydxs, alpha=0.8)\n",
    "        ax.set_ylim(bottom=min(0, min(dydxs) * 1.1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"queue_ingress_rate\"\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "graph_estimated_queue_ingress_rate(\n",
    "    INCAST_Q_DEPTHS_BY_BURST, BANDWIDTH_BITSPS, interp_delta=1e5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc479fb-5120-48c9-a132-6e3f6f4c3ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_aggregate_cwnd_across_bursts(\n",
    "    sender_to_cwnds_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "):\n",
    "    # We always ignore the first burst, since it is different than the others\n",
    "    # due to slow start.\n",
    "    if num_bursts == 1:\n",
    "        print(\n",
    "            \"No results because we ignore the frst burst, but there is only one burst.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Flatten all senders and bursts.\n",
    "    flattened_flows = []\n",
    "    # Throw away the first burst, because it always looks different.\n",
    "    for burst_idx in range(1, num_bursts):\n",
    "        # Find the earliest start time for a flow in this burst.\n",
    "        start_x = min(\n",
    "            bursts[burst_idx][0][0]\n",
    "            for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "        )\n",
    "        for bursts in sender_to_cwnds_by_burst_interp.values():\n",
    "            # Throw away bursts with no samples.\n",
    "            if bursts[burst_idx]:\n",
    "                flattened_flows.append(\n",
    "                    [\n",
    "                        # Make all bursts start at time 0.\n",
    "                        (sample[0] - start_x, *sample[1:])\n",
    "                        for sample in bursts[burst_idx]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    (\n",
    "        xs,\n",
    "        avg_ys,\n",
    "        stdev_ys,\n",
    "        min_ys,\n",
    "        max_ys,\n",
    "        percentiles_ys,\n",
    "        _,\n",
    "    ) = calculate_aggregate_metrics(flattened_flows, interp_delta, percentiles)\n",
    "\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(13, 3), nrows=1, ncols=2)\n",
    "\n",
    "    # Left graph\n",
    "    axes[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "    axes[0].fill_between(\n",
    "        xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "    )\n",
    "    axes[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    axes[0].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[0].set_xlabel(\"time (seconds)\")\n",
    "    axes[0].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[0].set_ylim(bottom=0)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Right graph\n",
    "    axes[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    for idx in range(1, percentiles_ys.shape[0]):\n",
    "        axes[1].fill_between(\n",
    "            xs,\n",
    "            percentiles_ys[idx - 1],\n",
    "            percentiles_ys[idx],\n",
    "            alpha=0.5,\n",
    "            label=f\"p{percentiles[idx]}\",\n",
    "        )\n",
    "    axes[1].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[1].set_xlabel(\"time (seconds)\")\n",
    "    axes[1].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[1].set_ylim(bottom=0)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"combined_cwnd_analysis\"\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "graph_aggregate_cwnd_across_bursts(\n",
    "    SENDER_TO_CWNDS_BY_BURST_INTERP, len(BURST_TIMES), INTERP_DELTA, PERCENTILES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3af6be-9dd4-4905-a35a-70ce61eecba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_total_cwnd(\n",
    "    sender_to_cwnds_by_burst_interp, burst_times, bdp_bytes, interp_delta\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(13, 3 * num_bursts), nrows=num_bursts, ncols=2\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        valid = [\n",
    "            bursts[burst_idx]\n",
    "            for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "            if bursts[burst_idx]\n",
    "        ]\n",
    "        xs, _, _, _, _, _, sum_ys = calculate_aggregate_metrics(\n",
    "            valid, interp_delta, percentiles=[]\n",
    "        )\n",
    "\n",
    "        ax[0].plot(\n",
    "            xs, sum_ys / 1e3, label=\"Total CWND of active connections\", alpha=0.8\n",
    "        )\n",
    "\n",
    "        # Draw a line at the BDP\n",
    "        bdp_kbytes = bdp_bytes / 1e3\n",
    "        ax[0].plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [bdp_kbytes, bdp_kbytes],\n",
    "            label=\"BDP\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax[0].set_title(f\"Total CWND in bytes: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax[0].set_xlabel(\"time (seconds)\")\n",
    "        ax[0].set_ylabel(\"kilobytes\")\n",
    "        ax[0].set_ylim(bottom=0)\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(\n",
    "            xs,\n",
    "            [y / bdp_bytes for y in sum_ys],\n",
    "            label=\"Total CWND as a multiple of BDP\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        ax[1].set_title(\n",
    "            f\"Total CWND in multiples of BDP: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax[1].set_xlabel(\"time (seconds)\")\n",
    "        ax[1].set_ylabel(\"multiples of the BDP\")\n",
    "        ax[1].set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"total_cwnd\")\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "BDP_BYTES = (\n",
    "    CONFIG[\"smallLinkBandwidthMbps\"] * 1e6 / 8 * 6 * CONFIG[\"delayPerLinkUs\"] / 1e6\n",
    ")\n",
    "graph_total_cwnd(SENDER_TO_CWNDS_BY_BURST_INTERP, BURST_TIMES, BDP_BYTES, INTERP_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c89e7-f7ef-4781-a107-41d52f7958f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_cwnd_change_cdf(sender_to_cwnds_by_burst, burst_times):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(5, 3 * num_bursts), nrows=num_bursts, ncols=1)\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        cwnd_down = []\n",
    "        cwnd_up = []\n",
    "        for sender_cwnds in sender_to_cwnds_by_burst.values():\n",
    "            if len(sender_cwnds[burst_idx]) < 2:\n",
    "                continue\n",
    "            _, sender_cwnds_burst = zip(*sender_cwnds[burst_idx])\n",
    "            # Compute percent difference\n",
    "            cwnd_changes = np.diff(sender_cwnds_burst) / sender_cwnds_burst[:-1] * 100\n",
    "            # Filter based on whether increase or decrease\n",
    "            cwnd_down.extend(abs(x) for x in cwnd_changes if x < 0)\n",
    "            cwnd_up.extend(x for x in cwnd_changes if x > 0)\n",
    "\n",
    "        # Plot CWND decreases\n",
    "        count, bins_count = np.histogram(cwnd_down, bins=len(cwnd_down))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            label=\"CWND decrease\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "        # Plot CWND increases\n",
    "        count, bins_count = np.histogram(cwnd_up, bins=len(cwnd_up))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            linestyle=\"dashed\",\n",
    "            label=\"CWND increase\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"CDF of CWND change (%): Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"CWND change (%)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(\n",
    "        OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"cwnd_change_cdf\"\n",
    "    )\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "graph_cwnd_change_cdf(SENDER_TO_CWNDS_BY_BURST, BURST_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716d23c-7a5c-41a1-bdcd-b8e7f6d09550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze congestion estimation\n",
    "\n",
    "\n",
    "def parse_congest_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 4\n",
    "    time_sec, acked_ecn_bytes, total_acked_bytes, alpha = parts\n",
    "    time_sec = float(time_sec)\n",
    "    acked_ecn_bytes = int(acked_ecn_bytes)\n",
    "    total_acked_bytes = int(total_acked_bytes)\n",
    "    alpha = float(alpha)\n",
    "    return time_sec, acked_ecn_bytes, total_acked_bytes, alpha\n",
    "\n",
    "\n",
    "def parse_congest(flp):\n",
    "    with open(flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        return [parse_congest_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def get_sender_to_congest_by_burst(out_dir, burst_times, flow_times):\n",
    "    return {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all congestion estimate samples for this sender\n",
    "            parse_congest(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            [burst_flow_times[parse_sender(flp)] for burst_flow_times in flow_times],\n",
    "            filter_on_flow_times=True,\n",
    "            earliest_sec=False,\n",
    "            bookend=True,\n",
    "        )\n",
    "        # Look up all congestion estimate log files.\n",
    "        for flp in [\n",
    "            path.join(out_dir, fln)\n",
    "            for fln in os.listdir(out_dir)\n",
    "            if fln.startswith(\"sender\") and fln.endswith(\"_congest.log\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def graph_dctcp_alpha(sender_to_congest_by_burst, burst_times):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            f\"Alpha of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"alpha\")\n",
    "\n",
    "        for sender, bursts in sender_to_congest_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, _, _, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(\n",
    "                xs,\n",
    "                ys,\n",
    "                \"o\",\n",
    "                markersize=1.5,\n",
    "                label=sender,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    out_flp = path.join(OUT_DIR_GRAPHS, path.basename(OUT_DIR) + \"_\" + \"alpha\")\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "SENDER_TO_CONGEST_BY_BURST = get_sender_to_congest_by_burst(\n",
    "    path.join(OUT_DIR, \"logs\"), BURST_TIMES, FLOW_TIMES\n",
    ")\n",
    "graph_dctcp_alpha(SENDER_TO_CONGEST_BY_BURST, BURST_TIMES)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "incast-analysis-venv",
   "language": "python",
   "name": "incast-analysis-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
