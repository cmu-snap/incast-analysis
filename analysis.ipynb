{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0bcbf-b498-45d5-a12a-fee2d4220a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# TODO: Add burstiness analysis from receiver pcap, flow level\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RUN = True\n",
    "else:\n",
    "    RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915fdcb-ffa2-4dc1-83d0-df65b094043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    EXP_DIR = \"/data_hdd/incast/out/15ms-200-3-TcpDctcp-10icwnd-0offset-none-rwnd1000000B-20tokens-4g-80ecn-1_0da\"\n",
    "    EXP = path.basename(EXP_DIR)\n",
    "    GRAPH_DIR = path.join(EXP_DIR, \"graphs\")\n",
    "    if not path.isdir(GRAPH_DIR):\n",
    "        os.makedirs(GRAPH_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d03cb-7e6d-4a8a-a28a-c39e3b2fc772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show(fig):\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not\n",
    "    # move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def save(graph_dir, prefix=None, suffix=None):\n",
    "    assert prefix is not None or suffix is not None\n",
    "    both_defined = prefix is not None and suffix is not None\n",
    "    out_flp = path.join(\n",
    "        graph_dir,\n",
    "        (\"\" if prefix is None else prefix)\n",
    "        + (\"_\" if both_defined else \"\")\n",
    "        + (\"\" if suffix is None else suffix),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_flp + \".pdf\")\n",
    "    plt.savefig(out_flp + \".png\", dpi=300)\n",
    "\n",
    "\n",
    "def get_axes(rows, width=10, cols=1):\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(width, 3 * rows), nrows=rows, ncols=cols)\n",
    "    if rows == 1:\n",
    "        axes = [axes]\n",
    "    elif cols == 1:\n",
    "        axes = axes.flatten()\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def filter_samples(samples, start, end):\n",
    "    return [sample for sample in samples if start <= sample[0] <= end]\n",
    "\n",
    "\n",
    "def separate_samples_into_bursts(\n",
    "    samples,\n",
    "    burst_times,\n",
    "    flow_times=None,\n",
    "    filter_on_flow_times=False,\n",
    "    bookend=True,\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    bursts = []\n",
    "\n",
    "    if filter_on_flow_times:\n",
    "        assert flow_times is not None\n",
    "    else:\n",
    "        assert flow_times is None\n",
    "        flow_times = [(None, None, None, None)] * num_bursts\n",
    "\n",
    "    for burst_idx, (\n",
    "        (burst_start, burst_end),\n",
    "        (flow_start, _, flow_end, _),\n",
    "    ) in enumerate(zip(burst_times, flow_times)):\n",
    "        burst = []\n",
    "        for sample in samples:\n",
    "            if burst_start <= sample[0] <= burst_end and (\n",
    "                not filter_on_flow_times or flow_start <= sample[0] <= flow_end\n",
    "            ):\n",
    "                # This sample is part of the current burst.\n",
    "                burst.append(sample)\n",
    "\n",
    "        # Insert a sample at precisely the start and end time for this burst,\n",
    "        # if possible.\n",
    "        if bookend:\n",
    "            start, end = (\n",
    "                (flow_start, flow_end)\n",
    "                if filter_on_flow_times\n",
    "                else (burst_start, burst_end)\n",
    "            )\n",
    "            if burst_idx > 0:\n",
    "                # Make sure that the burst has a sample at the start time\n",
    "                # Two case: Either we have no samples for this burst, so we take\n",
    "                # the last value from the previous burst, or we do have samples for\n",
    "                # this burst but not at the start time, so we also take the last\n",
    "                # value from the previous burst. In both cases, make sure there is\n",
    "                # a previous burst.\n",
    "                if (not burst and bursts[-1]) or (\n",
    "                    burst and burst[0][0] != start and bursts[-1]\n",
    "                ):\n",
    "                    burst.insert(0, (start, *bursts[-1][-1][1:]))\n",
    "            # Every burst should now have at least one sample: start.\n",
    "            # Note: This will fail if we have no data for the first burst.\n",
    "\n",
    "            if burst:\n",
    "                # Make sure that the burst has a sample at the end time\n",
    "                if burst[-1][0] != end:\n",
    "                    burst.append((end, *burst[-1][1:]))\n",
    "                # Every burst should now have at least two samples: start and end\n",
    "                assert len(burst) >= 2, (burst, start, end)\n",
    "\n",
    "        bursts.append(burst)\n",
    "    # Make sure we have the expected number of bursts\n",
    "    assert len(bursts) == num_bursts\n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a292b86-8cfd-42af-b6a5-1b316ec1a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_times_line(line):\n",
    "    # Format: <start time seconds> <end time seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    return [float(sec) for sec in parts]\n",
    "\n",
    "\n",
    "def get_burst_times(exp_dir):\n",
    "    with open(\n",
    "        path.join(exp_dir, \"logs\", \"burst_times.log\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        return [parse_times_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def get_config_json(exp_dir):\n",
    "    with open(path.join(exp_dir, \"config.json\"), \"r\", encoding=\"utf-8\") as fil:\n",
    "        return json.load(fil)\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    BURST_TIMES = get_burst_times(EXP_DIR)\n",
    "    # BURST_TIMES = [(start, (start + 0.03) if (end - start) > 0.03 else end) for start, end in BURST_TIMES]\n",
    "\n",
    "    NUM_BURSTS = len(BURST_TIMES)\n",
    "    CONFIG = get_config_json(EXP_DIR)\n",
    "    assert NUM_BURSTS == CONFIG[\"numBursts\"]\n",
    "\n",
    "    ideal_sec = CONFIG[\"bytesPerSender\"] * CONFIG[\"numSenders\"] / (\n",
    "        CONFIG[\"smallLinkBandwidthMbps\"] * 1e6 / 8\n",
    "    ) + (6 * CONFIG[\"delayPerLinkUs\"] / 1e6)\n",
    "    print(\n",
    "        \"Burst times:\",\n",
    "        f\"Ideal: {ideal_sec * 1e3:.4f} ms\",\n",
    "        *[\n",
    "            (\n",
    "                f\"{burst_idx + 1}: [{start} -> {end}] - \"\n",
    "                f\"{(end - start) * 1e3:.4f} ms - \"\n",
    "                f\"{(end - start) / ideal_sec * 100:.2f} %\"\n",
    "            )\n",
    "            for burst_idx, (start, end) in enumerate(BURST_TIMES)\n",
    "        ],\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68c936-ec67-4327-8d31-eb40619cb768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_depth_line(line):\n",
    "    # Format: <timestamp seconds> <num packets> <backlog time microseconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, packets = parts\n",
    "    time_sec = float(time_sec)\n",
    "    packets = int(packets)\n",
    "    # backlog_us = float(backlog_us)\n",
    "    return time_sec, packets  # , backlog_us\n",
    "\n",
    "\n",
    "def parse_mark_line(line):\n",
    "    # Format <timestamp seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 1\n",
    "    return (float(parts[0]), None)\n",
    "\n",
    "\n",
    "def parse_drop_line(line):\n",
    "    # Format: <timestamp seconds> <drop type>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, drop_type = parts\n",
    "    time_sec = float(time_sec)\n",
    "    drop_type = int(drop_type)\n",
    "    return time_sec, drop_type\n",
    "\n",
    "\n",
    "def get_depths_by_burst(exp_dir, queue_prefix, burst_times):\n",
    "    depth_samples = []\n",
    "    with open(\n",
    "        path.join(exp_dir, \"logs\", f\"{queue_prefix}_depth.log\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        depth_samples = [\n",
    "            parse_depth_line(line) for line in fil if line.strip()[0] != \"#\"\n",
    "        ]\n",
    "    return separate_samples_into_bursts(depth_samples, burst_times)\n",
    "\n",
    "\n",
    "def get_marks_by_burst(exp_dir, queue_prefix, burst_times):\n",
    "    mark_samples = []\n",
    "    with open(\n",
    "        path.join(exp_dir, \"logs\", f\"{queue_prefix}_mark.log\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        mark_samples = [parse_mark_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    return separate_samples_into_bursts(mark_samples, burst_times, bookend=False)\n",
    "\n",
    "\n",
    "def get_drops_by_burst(exp_dir, queue_prefix, burst_times):\n",
    "    drop_samples = []\n",
    "    with open(\n",
    "        path.join(exp_dir, \"logs\", f\"{queue_prefix}_drop.log\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        drop_samples = [parse_drop_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    return separate_samples_into_bursts(drop_samples, burst_times, bookend=False)\n",
    "\n",
    "\n",
    "def get_queue_metrics_by_burst(exp_dir, queue_name, burst_times):\n",
    "    queue_prefix = (\n",
    "        \"incast_queue\"\n",
    "        if queue_name == \"Incast Queue\"\n",
    "        else (\"uplink_queue\" if queue_name == \"Uplink Queue\" else None)\n",
    "    )\n",
    "    assert queue_prefix is not None\n",
    "    return {\n",
    "        \"depths\": get_depths_by_burst(exp_dir, queue_prefix, burst_times),\n",
    "        \"marks\": get_marks_by_burst(exp_dir, queue_prefix, burst_times),\n",
    "        \"drops\": get_drops_by_burst(exp_dir, queue_prefix, burst_times),\n",
    "    }\n",
    "\n",
    "\n",
    "def graph_queue(\n",
    "    queue_name,\n",
    "    depths_by_burst,\n",
    "    marks_by_burst,\n",
    "    drops_by_burst,\n",
    "    marking_threshold_packets,\n",
    "    capacity_packets,\n",
    "    num_bursts,\n",
    "    graph_dir,\n",
    "    prefix,\n",
    "):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, (ax, burst) in enumerate(zip(axes, depths_by_burst)):\n",
    "        # If there are marks, plot them...\n",
    "        if burst_idx < len(marks_by_burst) and marks_by_burst[burst_idx]:\n",
    "            mark_xs, _ = zip(*marks_by_burst[burst_idx])\n",
    "            mark_ys = [marking_threshold_packets] * len(mark_xs)\n",
    "            ax.plot(mark_xs, mark_ys, \"x\", color=\"orange\", label=\"ECN marks\", alpha=0.8)\n",
    "\n",
    "        # If there are drops, plot them...\n",
    "        if burst_idx < len(drops_by_burst) and drops_by_burst[burst_idx]:\n",
    "            drop_xs, _ = zip(*drops_by_burst[burst_idx])\n",
    "            drop_ys = [capacity_packets] * len(drop_xs)\n",
    "            ax.plot(drop_xs, drop_ys, \"x\", color=\"red\", label=\"Drops\", alpha=0.8)\n",
    "\n",
    "        # Plot depth\n",
    "        xs, ys = zip(*burst)\n",
    "        blue = \"tab:blue\"\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", color=blue, alpha=0.8)\n",
    "\n",
    "        # Draw a line at the marking threshold\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [marking_threshold_packets] * 2,\n",
    "            label=\"Marking threshold\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        # Draw a line at the queue capacity\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [capacity_packets] * 2,\n",
    "            label=\"Queue capacity\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"dotted\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{queue_name} Length: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"queue length (packets)\")\n",
    "        # ax.tick_params(axis='y', labelcolor=blue)\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.legend()\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"_\".join(queue_name.split(\" \")).lower())\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    MARKING_THRESHOLD = CONFIG[\"smallQueueMinThresholdPackets\"]\n",
    "    QUEUE_CAPACITY = CONFIG[\"smallQueueSizePackets\"]\n",
    "    INCAST_Q_METRICS = get_queue_metrics_by_burst(EXP_DIR, \"Incast Queue\", BURST_TIMES)\n",
    "    graph_queue(\n",
    "        \"Incast Queue\",\n",
    "        INCAST_Q_METRICS[\"depths\"],\n",
    "        INCAST_Q_METRICS[\"marks\"],\n",
    "        INCAST_Q_METRICS[\"drops\"],\n",
    "        MARKING_THRESHOLD,\n",
    "        QUEUE_CAPACITY,\n",
    "        NUM_BURSTS,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693eb0f-154e-4219-9602-4d14dc7c1928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_time_at_or_above_threshold_helper(depths, thresh, start_sec, end_sec):\n",
    "    # Identify crossover points and above regions points by filtering burst_samples.\n",
    "    above_regions = []\n",
    "    last_depth = None\n",
    "    last_cross_up = None\n",
    "    for x, depth in depths:\n",
    "        if depth < thresh:\n",
    "            if last_cross_up is not None:\n",
    "                above_regions.append((last_cross_up, x))\n",
    "                last_cross_up = None\n",
    "        elif depth >= thresh:\n",
    "            if last_depth is None or last_depth < thresh:\n",
    "                last_cross_up = x\n",
    "        last_depth = depth\n",
    "    if last_cross_up is not None:\n",
    "        above_regions.append((last_cross_up, end_sec))\n",
    "\n",
    "    above_sec = sum(\n",
    "        region_end_sec - region_start_sec\n",
    "        for region_start_sec, region_end_sec in above_regions\n",
    "    )\n",
    "    total_sec = end_sec - start_sec\n",
    "    return above_sec, total_sec, above_sec / total_sec * 100\n",
    "\n",
    "\n",
    "def calculate_time_at_or_above_threshold(depths_by_burst, burst_times, thresh):\n",
    "    return [\n",
    "        calculate_time_at_or_above_threshold_helper(depths, thresh, start_sec, end_sec)\n",
    "        for burst_idx, (depths, (start_sec, end_sec)) in enumerate(\n",
    "            zip(depths_by_burst, burst_times)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def print_q_above_thresh(depths_by_burst, burst_times, thresh, label):\n",
    "    num_bursts = len(burst_times)\n",
    "    for burst_idx, (above_sec, _, perc) in enumerate(\n",
    "        calculate_time_at_or_above_threshold(depths_by_burst, burst_times, thresh)\n",
    "    ):\n",
    "        print(\n",
    "            f\"Burst {burst_idx + 1} of {num_bursts} \"\n",
    "            f\"- Time above {label}: {above_sec * 1e3:.2f} ms ({perc:.2f}%)\"\n",
    "        )\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    print_q_above_thresh(\n",
    "        INCAST_Q_METRICS[\"depths\"], BURST_TIMES, MARKING_THRESHOLD, \"marking threshold\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0ea62-e968-44c0-8775-033b81ddae7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    print_q_above_thresh(INCAST_Q_METRICS[\"depths\"], BURST_TIMES, 1, \"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a77e5-9719-4168-beb2-5c8b61be1ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    print_q_above_thresh(\n",
    "        INCAST_Q_METRICS[\"depths\"], BURST_TIMES, QUEUE_CAPACITY * 0.9, \"90% capacity\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce597b6e-74ef-4963-9935-39603d0e34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    UPLINK_Q_METRICS = get_queue_metrics_by_burst(EXP_DIR, \"Uplink Queue\", BURST_TIMES)\n",
    "    graph_queue(\n",
    "        \"Uplink Queue\",\n",
    "        UPLINK_Q_METRICS[\"depths\"],\n",
    "        UPLINK_Q_METRICS[\"marks\"],\n",
    "        UPLINK_Q_METRICS[\"drops\"],\n",
    "        MARKING_THRESHOLD,\n",
    "        QUEUE_CAPACITY,\n",
    "        NUM_BURSTS,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be6075-4fbc-4b8a-88a0-d122b3db0d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_flow_times(flow_times_json):\n",
    "    burst_to_sender_to_flow_times = [\n",
    "        {\n",
    "            times[\"id\"]: (times[\"start\"], times[\"firstPacket\"], times[\"end\"], ip)\n",
    "            for ip, times in flows.items()\n",
    "        }\n",
    "        for burst, flows in sorted(flow_times_json.items(), key=lambda p: int(p[0]))\n",
    "    ]\n",
    "    sender_to_flow_times_by_burst = {}\n",
    "    for sender in burst_to_sender_to_flow_times[0].keys():\n",
    "        sender_flow_times_by_burst = []\n",
    "        for burst_idx in range(len(burst_to_sender_to_flow_times)):\n",
    "            sender_flow_times_by_burst.append(\n",
    "                burst_to_sender_to_flow_times[burst_idx][sender]\n",
    "            )\n",
    "        sender_to_flow_times_by_burst[sender] = sender_flow_times_by_burst\n",
    "    return sender_to_flow_times_by_burst\n",
    "\n",
    "\n",
    "def get_sender_to_flow_times_by_burst(exp_dir):\n",
    "    with open(\n",
    "        path.join(exp_dir, \"logs\", \"flow_times.json\"), \"r\", encoding=\"utf-8\"\n",
    "    ) as fil:\n",
    "        return parse_flow_times(json.load(fil))\n",
    "\n",
    "\n",
    "def get_active_conns_by_burst(sender_to_flow_times_by_burst, num_bursts):\n",
    "    active_conns_by_burst = []\n",
    "    for burst_idx in range(num_bursts):\n",
    "        times = [\n",
    "            flow_times_by_burst[burst_idx]\n",
    "            for flow_times_by_burst in sender_to_flow_times_by_burst.values()\n",
    "        ]\n",
    "        starts, _, ends, _ = zip(*times)\n",
    "        serialized = [(start, 1) for start in starts] + [(end, -1) for end in ends]\n",
    "        serialized = sorted(serialized, key=lambda p: p[0])\n",
    "        active = [serialized[0]]\n",
    "        for time, action in serialized[1:]:\n",
    "            active.append((time, active[-1][1] + action))\n",
    "        active_conns_by_burst.append(active)\n",
    "    return active_conns_by_burst\n",
    "\n",
    "\n",
    "def graph_active_connections(active_conns_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        xs, ys = zip(*active_conns_by_burst[burst_idx])\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Active connections over time: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"active connections\")\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"active_connections\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    SENDER_TO_FLOW_TIMES_BY_BURST = get_sender_to_flow_times_by_burst(EXP_DIR)\n",
    "    ACTIVE_CONNS_BY_BURST = get_active_conns_by_burst(\n",
    "        SENDER_TO_FLOW_TIMES_BY_BURST, NUM_BURSTS\n",
    "    )\n",
    "    graph_active_connections(ACTIVE_CONNS_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e9b9c-411e-4461-9869-5d3671dda229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_cdf_of_flow_duration(\n",
    "    sender_to_flow_times_by_burst, num_bursts, graph_dir, prefix\n",
    "):\n",
    "    fig, axes = get_axes(num_bursts, width=5)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        times = [\n",
    "            flow_times_by_burst[burst_idx]\n",
    "            for flow_times_by_burst in sender_to_flow_times_by_burst.values()\n",
    "        ]\n",
    "        durations = [end - start for start, _, end, _ in times]\n",
    "\n",
    "        count, bins_count = np.histogram(durations, bins=len(durations))\n",
    "        ax.plot(bins_count[1:], np.cumsum(count / sum(count)), alpha=0.8)\n",
    "\n",
    "        ax.set_title(f\"CDF of flow duration: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"duration (seconds)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1.01)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"flow_duration_cdf\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    graph_cdf_of_flow_duration(\n",
    "        SENDER_TO_FLOW_TIMES_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491fc08-1963-4a89-a561-3fdc27561b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_cwnd_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, cwnd_bytes = parts\n",
    "    time_sec = float(time_sec)\n",
    "    cwnd_bytes = int(cwnd_bytes)\n",
    "    return time_sec, cwnd_bytes\n",
    "\n",
    "\n",
    "def parse_cwnds(flp):\n",
    "    with open(flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        return [parse_cwnd_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def parse_sender(flp):\n",
    "    return int(path.basename(flp).split(\"_\")[0][6:])\n",
    "\n",
    "\n",
    "def get_sender_to_cwnds_by_burst(exp_dir, burst_times, sender_to_flow_times_by_burst):\n",
    "    return {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all CWND samples for this sender\n",
    "            parse_cwnds(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            sender_to_flow_times_by_burst[parse_sender(flp)],\n",
    "            filter_on_flow_times=True,\n",
    "            bookend=True,\n",
    "        )\n",
    "        for flp in [\n",
    "            path.join(exp_dir, \"logs\", fln)\n",
    "            for fln in os.listdir(path.join(exp_dir, \"logs\"))\n",
    "            if fln.startswith(\"sender\") and fln.endswith(\"_cwnd.log\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def graph_sender_cwnd(sender_to_cwnds_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            f\"CWND of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"CWND (bytes)\")\n",
    "\n",
    "        for sender, bursts in sender_to_cwnds_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(xs, ys, label=sender, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"cwnd\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    SENDER_TO_CWNDS_BY_BURST = get_sender_to_cwnds_by_burst(\n",
    "        EXP_DIR, BURST_TIMES, SENDER_TO_FLOW_TIMES_BY_BURST\n",
    "    )\n",
    "    graph_sender_cwnd(SENDER_TO_CWNDS_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d4e81-9f1e-41a6-bf4f-2f2fb660a178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspired by https://stackoverflow.com/questions/10058227/calculating-mean-of-arrays-with-different-lengths\n",
    "def tolerant_metrics(xs, arrays, interp_delta, percentiles):\n",
    "    # Map x value to index. Used to quickly determine where each array starts\n",
    "    # relative to the overall xs.\n",
    "    xs_map = {\n",
    "        round(x, int(math.log(interp_delta, 10))): idx for idx, x in enumerate(xs)\n",
    "    }\n",
    "\n",
    "    # Create 2d array to fit the largest array\n",
    "    combined_2d = np.ma.empty((len(xs), len(arrays)))\n",
    "    combined_2d.mask = True\n",
    "\n",
    "    for idx, array in enumerate(arrays):\n",
    "        # Look up this array's start position\n",
    "        start_idx = xs_map[round(array[0][0], int(math.log(interp_delta, 10)))]\n",
    "        combined_2d[start_idx : start_idx + len(array), idx] = list(zip(*array))[1]\n",
    "\n",
    "    return (\n",
    "        combined_2d.mean(axis=-1),\n",
    "        combined_2d.std(axis=-1),\n",
    "        combined_2d.min(axis=-1),\n",
    "        combined_2d.max(axis=-1),\n",
    "        np.nanpercentile(\n",
    "            np.ma.filled(np.ma.masked_where(combined_2d < 0, combined_2d), np.nan),\n",
    "            percentiles,\n",
    "            axis=-1,\n",
    "        ),\n",
    "        combined_2d.sum(axis=-1),\n",
    "    )\n",
    "\n",
    "\n",
    "def step_interp(old_xs, old_ys, new_xs):\n",
    "    # Lengths must be nonzero and agree.\n",
    "    assert len(old_xs) > 0\n",
    "    assert len(old_ys) > 0\n",
    "    assert len(new_xs) > 0\n",
    "    assert len(old_xs) == len(old_ys)\n",
    "    # xs must be strictly non-decreasing.\n",
    "    assert (np.diff(old_xs) >= 0).all(), np.diff(old_xs)\n",
    "    assert (np.diff(new_xs) >= 0).all()\n",
    "    # This is strictly interpolation, not extrapolation.\n",
    "    assert new_xs[0] >= old_xs[0]\n",
    "    assert new_xs[-1] <= old_xs[-1]\n",
    "\n",
    "    new_ys = np.empty(len(new_xs))\n",
    "    # Points to the next value in xs and ys that is past the current x we are\n",
    "    # interpolating.\n",
    "    old_idx = 0\n",
    "    for new_idx, new_x in enumerate(new_xs):\n",
    "        # Move old_idx forward until it is at a position where the next element\n",
    "        # in old_xs is strictly greater than new_x.\n",
    "        #\n",
    "        # old_idx will never grow larger than len(old_xs) - 2\n",
    "        while old_idx < len(old_xs) - 2 and new_x >= old_xs[old_idx + 1]:\n",
    "            old_idx += 1\n",
    "\n",
    "        # If old_idx is immediately before the last element in old_xs, then\n",
    "        # check manually if we need to advance old_idx to the last element in\n",
    "        # old_xs.\n",
    "        if old_idx == len(old_xs) - 2:\n",
    "            if new_x >= old_xs[len(old_xs) - 1]:\n",
    "                old_idx += 1\n",
    "\n",
    "        new_ys[new_idx] = old_ys[old_idx]\n",
    "\n",
    "    assert len(new_xs) == len(new_ys)\n",
    "    return new_ys\n",
    "\n",
    "\n",
    "def interpolate_flows_for_burst(\n",
    "    sender_to_x_by_burst, sender_to_x_by_burst_interp, burst_idx, interp_delta\n",
    "):\n",
    "    # Interpolate each flow at uniform intervals.\n",
    "    for sender, bursts in sender_to_x_by_burst.items():\n",
    "        if bursts[burst_idx]:\n",
    "            start_x = bursts[burst_idx][0][0]\n",
    "            end_x = bursts[burst_idx][-1][0]\n",
    "            new_xs = np.array(\n",
    "                [\n",
    "                    x / interp_delta\n",
    "                    for x in range(\n",
    "                        math.ceil(start_x * interp_delta),\n",
    "                        math.floor(end_x * interp_delta) + 1,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            assert len(bursts[burst_idx]) > 0\n",
    "            assert len(new_xs) > 0\n",
    "            new_ys = step_interp(*zip(*bursts[burst_idx]), new_xs)\n",
    "        else:\n",
    "            new_xs = np.array([])\n",
    "            new_ys = np.array([])\n",
    "        sender_to_x_by_burst_interp[sender].append(list(zip(new_xs, new_ys)))\n",
    "\n",
    "\n",
    "def get_sender_to_x_by_burst_interp(sender_to_x_by_burst, num_bursts, interp_delta):\n",
    "    sender_to_x_by_burst_interp = collections.defaultdict(list)\n",
    "    for burst_idx in range(num_bursts):\n",
    "        interpolate_flows_for_burst(\n",
    "            sender_to_x_by_burst,\n",
    "            sender_to_x_by_burst_interp,\n",
    "            burst_idx,\n",
    "            interp_delta,\n",
    "        )\n",
    "    for bursts_interp in sender_to_x_by_burst_interp.values():\n",
    "        assert len(bursts_interp) == num_bursts\n",
    "    return sender_to_x_by_burst_interp\n",
    "\n",
    "\n",
    "def get_metrics(\n",
    "    sender_to_x_by_burst_interp,\n",
    "    burst_idx,\n",
    "    interp_delta,\n",
    "    percentiles,\n",
    "):\n",
    "    # Throw away senders that do not have any samples for this burst.\n",
    "    valid = [\n",
    "        bursts[burst_idx]\n",
    "        for bursts in sender_to_x_by_burst_interp.values()\n",
    "        if bursts[burst_idx]\n",
    "    ]\n",
    "    if len(valid) != len(sender_to_x_by_burst_interp):\n",
    "        print(\n",
    "            f\"Warning: Burst {burst_idx} has \"\n",
    "            f\"{len(valid)}/{len(sender_to_x_by_burst_interp)} \"\n",
    "            \"senders with at least one sample.\"\n",
    "        )\n",
    "    return get_metrics_helper(valid, interp_delta, percentiles)\n",
    "\n",
    "\n",
    "def get_metrics_helper(\n",
    "    valid,\n",
    "    interp_delta,\n",
    "    percentiles,\n",
    "):\n",
    "    # Determine the overall x-axis range for this burst, across all valid senders.\n",
    "    start_x = min(samples[0][0] for samples in valid)\n",
    "    end_x = max(samples[-1][0] for samples in valid)\n",
    "    xs = np.array(\n",
    "        [\n",
    "            x / interp_delta\n",
    "            for x in range(\n",
    "                math.floor(start_x * interp_delta), math.ceil(end_x * interp_delta) + 1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate and verify metrics.\n",
    "    avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys = tolerant_metrics(\n",
    "        xs, valid, interp_delta, percentiles\n",
    "    )\n",
    "    assert len(xs) == len(avg_ys)\n",
    "    assert len(xs) == len(stdev_ys)\n",
    "    assert len(xs) == len(min_ys)\n",
    "    assert len(xs) == len(max_ys)\n",
    "    assert len(xs) == percentiles_ys.shape[1]\n",
    "    assert len(xs) == len(sum_ys)\n",
    "\n",
    "    return xs, avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys\n",
    "\n",
    "\n",
    "def get_metrics_by_burst(\n",
    "    sender_to_x_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "):\n",
    "    return [\n",
    "        get_metrics(\n",
    "            sender_to_x_by_burst_interp,\n",
    "            burst_idx,\n",
    "            interp_delta,\n",
    "            percentiles,\n",
    "        )\n",
    "        for burst_idx in range(num_bursts)\n",
    "    ]\n",
    "\n",
    "\n",
    "def graph_cwnd_metrics(\n",
    "    cwnd_metrics_by_burst, num_bursts, percentiles, graph_dir, prefix\n",
    "):\n",
    "    fig, axes = get_axes(num_bursts, width=13, cols=2)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        xs, avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, _ = cwnd_metrics_by_burst[\n",
    "            burst_idx\n",
    "        ]\n",
    "\n",
    "        # Left graph\n",
    "        ax[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "        ax[0].fill_between(\n",
    "            xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "        )\n",
    "        ax[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "        ax[0].set_title(\n",
    "            f\"CWND of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax[0].set_xlabel(\"time (seconds)\")\n",
    "        ax[0].set_ylabel(\"CWND (bytes)\")\n",
    "        ax[0].set_ylim(bottom=0)\n",
    "        ax[0].legend()\n",
    "\n",
    "        # Right graph\n",
    "        ax[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "        for idx in range(1, percentiles_ys.shape[0]):\n",
    "            ax[1].fill_between(\n",
    "                xs,\n",
    "                percentiles_ys[idx - 1],\n",
    "                percentiles_ys[idx],\n",
    "                alpha=0.5,\n",
    "                label=f\"p{percentiles[idx]}\",\n",
    "            )\n",
    "        ax[1].set_title(\n",
    "            f\"CWND of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax[1].set_xlabel(\"time (seconds)\")\n",
    "        ax[1].set_ylabel(\"CWND (bytes)\")\n",
    "        ax[1].set_ylim(bottom=0)\n",
    "        ax[1].legend()\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"cwnd_analysis\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    INTERP_DELTA = 1e5\n",
    "    PERCENTILES = [0, 25, 50, 75, 95, 100]\n",
    "    SENDER_TO_CWNDS_BY_BURST_INTERP = get_sender_to_x_by_burst_interp(\n",
    "        SENDER_TO_CWNDS_BY_BURST, NUM_BURSTS, INTERP_DELTA\n",
    "    )\n",
    "    CWND_METRICS_BY_BURST = get_metrics_by_burst(\n",
    "        SENDER_TO_CWNDS_BY_BURST_INTERP, NUM_BURSTS, INTERP_DELTA, PERCENTILES\n",
    "    )\n",
    "    graph_cwnd_metrics(\n",
    "        CWND_METRICS_BY_BURST,\n",
    "        NUM_BURSTS,\n",
    "        PERCENTILES,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19dd8b-4419-42fd-8d99-e372161a95c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_average_queue_depth(\n",
    "    depths_by_burst, interp_delta, bandwidth_bps, bytes_per_packet\n",
    "):\n",
    "    avg_q_depth_by_burst = []\n",
    "    for depths in depths_by_burst:\n",
    "        old_xs, old_ys = zip(*depths)\n",
    "        start_x = old_xs[0]\n",
    "        end_x = old_xs[-1]\n",
    "        new_xs = np.array(\n",
    "            [\n",
    "                x / interp_delta\n",
    "                for x in range(\n",
    "                    math.ceil(start_x * interp_delta),\n",
    "                    math.floor(end_x * interp_delta) + 1,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        new_ys = step_interp(old_xs, old_ys, new_xs)\n",
    "        avg_q_packets = new_ys.mean()\n",
    "        avg_q_bytes = avg_q_packets * bytes_per_packet\n",
    "        avg_q_us = avg_q_bytes / (bandwidth_bps / 8) * 1e6\n",
    "        avg_q_depth_by_burst.append((avg_q_packets, avg_q_bytes, avg_q_us))\n",
    "    return avg_q_depth_by_burst\n",
    "\n",
    "\n",
    "def print_avg_q_depth(\n",
    "    depths_by_burst, num_bursts, interp_delta, bandwidth_bps, bytes_per_packet\n",
    "):\n",
    "    for burst_idx, (\n",
    "        avg_q_packets,\n",
    "        avg_q_bytes,\n",
    "        avg_q_us,\n",
    "    ) in enumerate(\n",
    "        calculate_average_queue_depth(\n",
    "            depths_by_burst, interp_delta, bandwidth_bps, bytes_per_packet\n",
    "        )\n",
    "    ):\n",
    "        print(\n",
    "            f\"Burst {burst_idx + 1} of {num_bursts} - \"\n",
    "            f\"Average queue depth: {avg_q_packets:.2f} packets, \"\n",
    "            f\"{avg_q_bytes:.2f} bytes, {avg_q_us:.2f} us\"\n",
    "        )\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    BYTES_PER_PACKET = 1500\n",
    "    BANDWIDTH_BITSPS = CONFIG[\"smallLinkBandwidthMbps\"] * 1e6\n",
    "    print_avg_q_depth(\n",
    "        INCAST_Q_METRICS[\"depths\"],\n",
    "        NUM_BURSTS,\n",
    "        INTERP_DELTA,\n",
    "        BANDWIDTH_BITSPS,\n",
    "        BYTES_PER_PACKET,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2817c7b-0ee0-4ce1-9282-dd6c1b300342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_estimated_queue_ingress_rate(\n",
    "    depths_by_burst,\n",
    "    num_bursts,\n",
    "    bandwidth_bps,\n",
    "    bytes_per_packet,\n",
    "    interp_delta,\n",
    "    graph_dir,\n",
    "    prefix,\n",
    "):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, (ax, depths) in enumerate(zip(axes, depths_by_burst)):\n",
    "        old_xs, old_ys = zip(*depths)\n",
    "        start_x = old_xs[0]\n",
    "        end_x = old_xs[-1]\n",
    "        new_xs = np.array(\n",
    "            [\n",
    "                x / interp_delta\n",
    "                for x in range(\n",
    "                    math.ceil(start_x * interp_delta),\n",
    "                    math.floor(end_x * interp_delta) + 1,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        new_ys = step_interp(old_xs, old_ys, new_xs)\n",
    "        new_ys *= 8 * bytes_per_packet\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Estimated queue ingress rate: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"ingress rate (Gbps)\")\n",
    "\n",
    "        dydxs = np.gradient(new_ys, new_xs)\n",
    "        # If queue is not empty, then it is by definition draining at the\n",
    "        # bandwidth. So if y is not 0, then add back the bandwidth to the\n",
    "        # gradient to calculate the true ingress rate instead of the net rate.\n",
    "        dydxs = np.array(\n",
    "            [\n",
    "                dydx if y == 0 else (dydx + bandwidth_bps)\n",
    "                for dydx, y in zip(dydxs, new_ys)\n",
    "            ]\n",
    "        )\n",
    "        dydxs /= 1e9\n",
    "\n",
    "        ax.plot(new_xs, dydxs, alpha=0.8)\n",
    "        ax.set_ylim(bottom=min(0, min(dydxs) * 1.1))\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"queue_ingress_rate\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    graph_estimated_queue_ingress_rate(\n",
    "        INCAST_Q_METRICS[\"depths\"],\n",
    "        NUM_BURSTS,\n",
    "        BANDWIDTH_BITSPS,\n",
    "        BYTES_PER_PACKET,\n",
    "        INTERP_DELTA,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc479fb-5120-48c9-a132-6e3f6f4c3ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cwnd_metrics_across_bursts(\n",
    "    sender_to_cwnds_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "):\n",
    "    # We always ignore the first burst, since it is different than the others\n",
    "    # due to slow start.\n",
    "    if num_bursts == 1:\n",
    "        print(\n",
    "            \"No results because we ignore the frst burst, but there is only one burst.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Flatten all senders and bursts.\n",
    "    flattened_flows = []\n",
    "    # Throw away the first burst, because it always looks different.\n",
    "    for burst_idx in range(1, num_bursts):\n",
    "        # Find the earliest start time for a flow in this burst.\n",
    "        start_x = min(\n",
    "            bursts[burst_idx][0][0]\n",
    "            for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "        )\n",
    "        for bursts in sender_to_cwnds_by_burst_interp.values():\n",
    "            # Throw away bursts with no samples.\n",
    "            if bursts[burst_idx]:\n",
    "                flattened_flows.append(\n",
    "                    [\n",
    "                        # Make all bursts start at time 0.\n",
    "                        (sample[0] - start_x, *sample[1:])\n",
    "                        for sample in bursts[burst_idx]\n",
    "                    ]\n",
    "                )\n",
    "    return get_metrics_helper(flattened_flows, interp_delta, percentiles)\n",
    "\n",
    "\n",
    "def graph_aggregate_cwnd_across_bursts(\n",
    "    cwnd_metrics_across_bursts,\n",
    "    percentiles,\n",
    "    graph_dir,\n",
    "    prefix,\n",
    "):\n",
    "    fig, axes = get_axes(rows=1, width=13, cols=2)\n",
    "    axes = axes[0]\n",
    "\n",
    "    xs, avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, _ = cwnd_metrics_across_bursts\n",
    "\n",
    "    # Left graph\n",
    "    axes[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "    axes[0].fill_between(\n",
    "        xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "    )\n",
    "    axes[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    axes[0].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[0].set_xlabel(\"time (seconds)\")\n",
    "    axes[0].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[0].set_ylim(bottom=0)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Right graph\n",
    "    axes[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    for idx in range(1, percentiles_ys.shape[0]):\n",
    "        axes[1].fill_between(\n",
    "            xs,\n",
    "            percentiles_ys[idx - 1],\n",
    "            percentiles_ys[idx],\n",
    "            alpha=0.5,\n",
    "            label=f\"p{percentiles[idx]}\",\n",
    "        )\n",
    "    axes[1].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[1].set_xlabel(\"time (seconds)\")\n",
    "    axes[1].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[1].set_ylim(bottom=0)\n",
    "    axes[1].legend()\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"combined_cwnd_analysis\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    CWND_METRICS_ACROSS_BURSTS = get_cwnd_metrics_across_bursts(\n",
    "        SENDER_TO_CWNDS_BY_BURST_INTERP, NUM_BURSTS, INTERP_DELTA, PERCENTILES\n",
    "    )\n",
    "    graph_aggregate_cwnd_across_bursts(\n",
    "        CWND_METRICS_ACROSS_BURSTS,\n",
    "        PERCENTILES,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3af6be-9dd4-4905-a35a-70ce61eecba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_total_cwnd(\n",
    "    cwnd_metrics_by_burst,\n",
    "    num_bursts,\n",
    "    bdp_bytes,\n",
    "    graph_dir,\n",
    "    prefix,\n",
    "):\n",
    "    fig, axes = get_axes(num_bursts, width=13, cols=2)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        xs, _, _, _, _, _, sum_ys = cwnd_metrics_by_burst[burst_idx]\n",
    "\n",
    "        ax[0].plot(\n",
    "            xs, sum_ys / 1e3, label=\"Total CWND of active connections\", alpha=0.8\n",
    "        )\n",
    "\n",
    "        # Draw a line at the BDP\n",
    "        bdp_kbytes = bdp_bytes / 1e3\n",
    "        ax[0].plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [bdp_kbytes, bdp_kbytes],\n",
    "            label=\"BDP\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax[0].set_title(f\"Total CWND in bytes: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax[0].set_xlabel(\"time (seconds)\")\n",
    "        ax[0].set_ylabel(\"kilobytes\")\n",
    "        ax[0].set_ylim(bottom=0)\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(\n",
    "            xs,\n",
    "            [y / bdp_bytes for y in sum_ys],\n",
    "            label=\"Total CWND as a multiple of BDP\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        ax[1].set_title(\n",
    "            f\"Total CWND in multiples of BDP: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax[1].set_xlabel(\"time (seconds)\")\n",
    "        ax[1].set_ylabel(\"multiples of the BDP\")\n",
    "        ax[1].set_ylim(bottom=0)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"total_cwnd\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    BDP_BYTES = (\n",
    "        CONFIG[\"smallLinkBandwidthMbps\"] * 1e6 / 8 * 6 * CONFIG[\"delayPerLinkUs\"] / 1e6\n",
    "    )\n",
    "    graph_total_cwnd(\n",
    "        CWND_METRICS_BY_BURST,\n",
    "        NUM_BURSTS,\n",
    "        BDP_BYTES,\n",
    "        GRAPH_DIR,\n",
    "        EXP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c89e7-f7ef-4781-a107-41d52f7958f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_cwnd_change_cdf(sender_to_cwnds_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts, width=5)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        cwnd_down = []\n",
    "        cwnd_up = []\n",
    "        for sender_cwnds in sender_to_cwnds_by_burst.values():\n",
    "            if len(sender_cwnds[burst_idx]) < 2:\n",
    "                continue\n",
    "            _, sender_cwnds_burst = zip(*sender_cwnds[burst_idx])\n",
    "            # Compute percent difference\n",
    "            cwnd_changes = np.diff(sender_cwnds_burst) / sender_cwnds_burst[:-1] * 100\n",
    "            # Filter based on whether increase or decrease\n",
    "            cwnd_down.extend(abs(x) for x in cwnd_changes if x < 0)\n",
    "            cwnd_up.extend(x for x in cwnd_changes if x > 0)\n",
    "\n",
    "        # Plot CWND decreases\n",
    "        count, bins_count = np.histogram(cwnd_down, bins=len(cwnd_down))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            label=\"CWND decrease\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "        # Plot CWND increases\n",
    "        count, bins_count = np.histogram(cwnd_up, bins=len(cwnd_up))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            linestyle=\"dashed\",\n",
    "            label=\"CWND increase\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"CDF of CWND change (%): Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"CWND change (%)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1.01)\n",
    "        ax.legend()\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"cwnd_change_cdf\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    graph_cwnd_change_cdf(SENDER_TO_CWNDS_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716d23c-7a5c-41a1-bdcd-b8e7f6d09550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_congest_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 4\n",
    "    time_sec, acked_ecn_bytes, total_acked_bytes, alpha = parts\n",
    "    time_sec = float(time_sec)\n",
    "    acked_ecn_bytes = int(acked_ecn_bytes)\n",
    "    total_acked_bytes = int(total_acked_bytes)\n",
    "    alpha = float(alpha)\n",
    "    return time_sec, acked_ecn_bytes, total_acked_bytes, alpha\n",
    "\n",
    "\n",
    "def parse_congest(flp):\n",
    "    with open(flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        return [parse_congest_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def get_sender_to_congest_by_burst(exp_dir, burst_times, sender_to_flow_times_by_burst):\n",
    "    return {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all congestion estimate samples for this sender\n",
    "            parse_congest(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            sender_to_flow_times_by_burst[parse_sender(flp)],\n",
    "            filter_on_flow_times=True,\n",
    "            bookend=True,\n",
    "        )\n",
    "        # Look up all congestion estimate log files.\n",
    "        for flp in [\n",
    "            path.join(exp_dir, \"logs\", fln)\n",
    "            for fln in os.listdir(path.join(exp_dir, \"logs\"))\n",
    "            if fln.startswith(\"sender\") and fln.endswith(\"_congest.log\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def graph_sender_dctcp_alpha(sender_to_congest_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            f\"Alpha of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"alpha\")\n",
    "\n",
    "        for sender, bursts in sender_to_congest_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, _, _, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(\n",
    "                xs,\n",
    "                ys,\n",
    "                \"o\",\n",
    "                markersize=1.5,\n",
    "                label=sender,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"dctcp_alpha\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    SENDER_TO_CONGEST_BY_BURST = get_sender_to_congest_by_burst(\n",
    "        EXP_DIR, BURST_TIMES, SENDER_TO_FLOW_TIMES_BY_BURST\n",
    "    )\n",
    "    graph_sender_dctcp_alpha(SENDER_TO_CONGEST_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4025c57-8dac-45ee-b250-968fa5d18ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_rtt_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, rtt_us = parts\n",
    "    time_sec = float(time_sec)\n",
    "    rtt_us = int(rtt_us)\n",
    "    return time_sec, rtt_us\n",
    "\n",
    "\n",
    "def parse_rtts(flp):\n",
    "    with open(flp, \"r\", encoding=\"utf-8\") as fil:\n",
    "        return [parse_rtt_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def get_sender_to_rtts_by_burst(exp_dir, burst_times, sender_to_flow_times_by_burst):\n",
    "    return {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all congestion estimate samples for this sender\n",
    "            parse_rtts(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            sender_to_flow_times_by_burst[parse_sender(flp)],\n",
    "            filter_on_flow_times=True,\n",
    "            bookend=True,\n",
    "        )\n",
    "        # Look up all congestion estimate log files.\n",
    "        for flp in [\n",
    "            path.join(exp_dir, \"logs\", fln)\n",
    "            for fln in os.listdir(path.join(exp_dir, \"logs\"))\n",
    "            if fln.startswith(\"sender\") and fln.endswith(\"_rtt.log\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def graph_sender_rtt(sender_to_rtts_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            \"Sender-measured RTT of active connections: \"\n",
    "            f\"Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"Sender-measured RTT (us)\")\n",
    "\n",
    "        for sender, bursts in sender_to_rtts_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(xs, ys, \"o\", markersize=1.5, label=sender, alpha=0.8)\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"rtt\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    SENDER_TO_RTTS_BY_BURST = get_sender_to_rtts_by_burst(\n",
    "        EXP_DIR, BURST_TIMES, SENDER_TO_FLOW_TIMES_BY_BURST\n",
    "    )\n",
    "    graph_sender_rtt(SENDER_TO_RTTS_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a6ad7-5cf1-4303-bb80-416bdcf66773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_rtt_cdf(sender_to_rtts_by_burst, num_bursts, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts, width=5)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        rtt_us = [\n",
    "            x[1]\n",
    "            for sender_rtts in sender_to_rtts_by_burst.values()\n",
    "            for x in sender_rtts[burst_idx]\n",
    "        ]\n",
    "\n",
    "        # Plot CDF of ACK size across all senders\n",
    "        count, bins_count = np.histogram(rtt_us, bins=len(rtt_us))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            label=\"ACKed MSS\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"CDF of RTT (us): Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"RTT (us)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1.01)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"rtt_cdf\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    graph_rtt_cdf(SENDER_TO_RTTS_BY_BURST, NUM_BURSTS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906707b7-ec32-48d4-9449-26a71f9b04e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_ack_size_cdf(sender_to_congest_by_burst, num_bursts, mss, graph_dir, prefix):\n",
    "    fig, axes = get_axes(num_bursts, width=5)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ack_bytes = [\n",
    "            b[2] / mss\n",
    "            for sender_congests in sender_to_congest_by_burst.values()\n",
    "            for b in sender_congests[burst_idx]\n",
    "        ]\n",
    "\n",
    "        # Plot CDF of ACK size across all senders\n",
    "        count, bins_count = np.histogram(ack_bytes, bins=len(ack_bytes))\n",
    "        ax.plot(\n",
    "            bins_count[1:],\n",
    "            np.cumsum(count / sum(count)),\n",
    "            alpha=0.8,\n",
    "            label=\"ACKed MSS\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"CDF of ACKed MSS: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"ACKed MSS\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1.01)\n",
    "\n",
    "    show(fig)\n",
    "    save(graph_dir, prefix, suffix=\"acks_cdf\")\n",
    "\n",
    "\n",
    "if RUN:\n",
    "    MSS = 1448\n",
    "    graph_ack_size_cdf(SENDER_TO_CONGEST_BY_BURST, NUM_BURSTS, MSS, GRAPH_DIR, EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4494d04-56f5-447e-805b-2fa58e259a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_metrics_for_exp(\n",
    "    exp_dir,\n",
    "    interp_delta=1e5,\n",
    "    percentiles=[0, 25, 50, 75, 95, 100],\n",
    "    bytes_per_packet=15000,\n",
    "):\n",
    "    config = get_config_json(exp_dir)\n",
    "    num_bursts = config[\"numBursts\"]\n",
    "    burst_times = get_burst_times(exp_dir)\n",
    "    sender_to_flow_times_by_burst = get_sender_to_flow_times_by_burst(exp_dir)\n",
    "    sender_to_cwnds_by_burst = get_sender_to_cwnds_by_burst(\n",
    "        exp_dir, burst_times, sender_to_flow_times_by_burst\n",
    "    )\n",
    "    sender_to_cwnds_by_burst_interp = get_sender_to_x_by_burst_interp(\n",
    "        sender_to_cwnds_by_burst, num_bursts, interp_delta\n",
    "    )\n",
    "    sender_to_rtts_by_burst = get_sender_to_rtts_by_burst(\n",
    "        exp_dir, burst_times, sender_to_flow_times_by_burst\n",
    "    )\n",
    "    incast_q_metrics = get_queue_metrics_by_burst(exp_dir, \"Incast Queue\", burst_times)\n",
    "    uplink_q_metrics = get_queue_metrics_by_burst(exp_dir, \"Uplink Queue\", burst_times)\n",
    "    return {\n",
    "        \"exp_dir\": exp_dir,\n",
    "        \"config\": config,\n",
    "        \"burst_times\": burst_times,\n",
    "        \"sender_to_flow_times_by_burst\": sender_to_flow_times_by_burst,\n",
    "        \"active_conns_by_burst\": get_active_conns_by_burst(\n",
    "            sender_to_flow_times_by_burst, num_bursts\n",
    "        ),\n",
    "        \"ideal_sec\": (\n",
    "            config[\"bytesPerSender\"]\n",
    "            * config[\"numSenders\"]\n",
    "            / (config[\"smallLinkBandwidthMbps\"] * 1e6 / 8)\n",
    "            + (6 * config[\"delayPerLinkUs\"] / 1e6)\n",
    "        ),\n",
    "        \"incast_queue\": incast_q_metrics,\n",
    "        \"uplink_queue\": uplink_q_metrics,\n",
    "        \"sender_to_cwnds_by_burst\": sender_to_cwnds_by_burst,\n",
    "        \"sender_to_cwnds_by_burst_interp\": sender_to_cwnds_by_burst_interp,\n",
    "        \"cwnd_metrics_by_burst\": get_metrics_by_burst(\n",
    "            sender_to_cwnds_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "        ),\n",
    "        \"cwnd_metrics_across_bursts\": get_cwnd_metrics_across_bursts(\n",
    "            sender_to_cwnds_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "        ),\n",
    "        \"sender_to_congest_by_burst\": get_sender_to_congest_by_burst(\n",
    "            exp_dir, burst_times, sender_to_flow_times_by_burst\n",
    "        ),\n",
    "        \"sender_to_rtts_by_burst\": sender_to_rtts_by_burst,\n",
    "        \"sender_to_rtts_by_burst_interp\": get_sender_to_x_by_burst_interp(\n",
    "            sender_to_rtts_by_burst, num_bursts, interp_delta\n",
    "        ),\n",
    "        \"incast_q_above_empty\": calculate_time_at_or_above_threshold(\n",
    "            incast_q_metrics[\"depths\"],\n",
    "            burst_times,\n",
    "            1,\n",
    "        ),\n",
    "        \"incast_q_above_mark\": calculate_time_at_or_above_threshold(\n",
    "            incast_q_metrics[\"depths\"],\n",
    "            burst_times,\n",
    "            config[\"smallQueueMinThresholdPackets\"],\n",
    "        ),\n",
    "        \"incast_q_above_90\": calculate_time_at_or_above_threshold(\n",
    "            incast_q_metrics[\"depths\"],\n",
    "            burst_times,\n",
    "            config[\"smallQueueSizePackets\"] * 0.9,\n",
    "        ),\n",
    "        \"incast_q_avg_depth_by_burst\": calculate_average_queue_depth(\n",
    "            incast_q_metrics[\"depths\"],\n",
    "            interp_delta,\n",
    "            config[\"smallLinkBandwidthMbps\"] * 1e6,\n",
    "            bytes_per_packet,\n",
    "        ),\n",
    "        \"uplink_q_avg_depth_by_burst\": calculate_average_queue_depth(\n",
    "            uplink_q_metrics[\"depths\"],\n",
    "            interp_delta,\n",
    "            config[\"largeLinkBandwidthMbps\"] * 1e6,\n",
    "            bytes_per_packet,\n",
    "        ),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "incast-analysis-venv",
   "language": "python",
   "name": "incast-analysis-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
