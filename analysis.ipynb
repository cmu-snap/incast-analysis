{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d03cb-7e6d-4a8a-a28a-c39e3b2fc772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.close()       \n",
    "\n",
    "\n",
    "# TODO: Add burstiness analysis from receiver pcap, flow level\n",
    "\n",
    "\n",
    "def parse_times_line(line):\n",
    "    # Format: <start time seconds> <end time seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    return [float(sec) for sec in parts]\n",
    "\n",
    "\n",
    "def parse_burst_times(out_dir):\n",
    "    with open(path.join(out_dir, \"log\", \"burst_times.log\"), \"r\") as fil:\n",
    "        return [parse_times_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def filter_samples(samples, start, end):\n",
    "    return [sample for sample in samples if start <= sample[0] <= end]\n",
    "\n",
    "\n",
    "def separate_samples_into_bursts(\n",
    "    samples,\n",
    "    burst_times,\n",
    "    flow_times=None,\n",
    "    filter_on_flow_times=False,\n",
    "    bookend=True,\n",
    "    earliest_sec=None,\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    bursts = []\n",
    "\n",
    "    if filter_on_flow_times:\n",
    "        assert flow_times is not None\n",
    "    else:\n",
    "        assert flow_times is None\n",
    "        flow_times = [(None, None, None)] * num_bursts\n",
    "\n",
    "    for burst_idx, ((burst_start, burst_end), (flow_start, flow_end, _)) in enumerate(\n",
    "        zip(burst_times, flow_times)\n",
    "    ):\n",
    "        burst = []\n",
    "        for sample in samples:\n",
    "            if burst_start <= sample[0] <= burst_end and (\n",
    "                not filter_on_flow_times or flow_start <= sample[0] <= flow_end\n",
    "            ):\n",
    "                # This sample is part of the current burst.\n",
    "                burst.append(sample)\n",
    "\n",
    "        # Insert a sample at precisely the start and end time for this burst, if possible.\n",
    "        if bookend:\n",
    "            start, end = (\n",
    "                (flow_start, flow_end)\n",
    "                if filter_on_flow_times\n",
    "                else (burst_start, burst_end)\n",
    "            )\n",
    "            if burst_idx > 0:\n",
    "                # Make sure that the burst has a sample at the start time\n",
    "                # Two case: Either we have no samples for this burst, so we take\n",
    "                # the last value from the previous burst, or we do have samples for\n",
    "                # this burst but not at the start time, so we also take the last\n",
    "                # value from the previous burst. In both cases, make sure there is\n",
    "                # a previous burst.\n",
    "                if (not burst and bursts[-1]) or (\n",
    "                    burst and burst[0][0] != start and bursts[-1]\n",
    "                ):\n",
    "                    burst.insert(0, (start, *bursts[-1][-1][1:]))\n",
    "            # Every burst should now have at least one sample: start.\n",
    "            # Note: This will fail if we have no data for the first burst.\n",
    "\n",
    "            if burst:\n",
    "                # Make sure that the burst has a sample at the end time\n",
    "                if burst[-1][0] != end:\n",
    "                    burst.append((end, *burst[-1][1:]))\n",
    "                # Every burst should now have at least two samples: start and end\n",
    "                assert len(burst) >= 2, (burst, start, end)\n",
    "\n",
    "        bursts.append(burst)\n",
    "    # Make sure we have the expected number of bursts\n",
    "    assert len(bursts) == num_bursts\n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915fdcb-ffa2-4dc1-83d0-df65b094043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"/data_hdd/incast/out/15-200-1-dctcp-icwnd10p\"\n",
    "BURST_TIMES = parse_burst_times(OUT_DIR)\n",
    "# BURST_TIMES = [(start, (start + 0.03) if (end - start) > 0.03 else end) for start, end in BURST_TIMES]\n",
    "print(\"\\n\".join(str(times) for times in BURST_TIMES))\n",
    "\n",
    "MARKING_THRESHOLD = 80\n",
    "QUEUE_CAPACITY = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d95142-2dd1-482d-bdbd-08bb940ff90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_queue_line(line):\n",
    "    # Format: <timestamp seconds> <num packets> <backlog time microseconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, packets = parts\n",
    "    time_sec = float(time_sec)\n",
    "    packets = int(packets)\n",
    "    # backlog_us = float(backlog_us)\n",
    "    return time_sec, packets  # , backlog_us\n",
    "\n",
    "\n",
    "def parse_mark_line(line):\n",
    "    # Format <timestamp seconds>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 1\n",
    "    return (float(parts[0]), None)\n",
    "\n",
    "\n",
    "def parse_drop_line(line):\n",
    "    # Format: <timestamp seconds> <drop type>\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, drop_type = parts\n",
    "    time_sec = float(time_sec)\n",
    "    drop_type = int(drop_type)\n",
    "    return time_sec, drop_type\n",
    "\n",
    "\n",
    "def graph_queue(\n",
    "    out_dir, queue_name, burst_times, marking_threshold_packets, capacity_packets\n",
    "):\n",
    "    queue_prefix = (\n",
    "        \"incast_queue\"\n",
    "        if queue_name == \"Incast Queue\"\n",
    "        else (\"uplink_queue\" if queue_name == \"Uplink Queue\" else None)\n",
    "    )\n",
    "    assert queue_prefix is not None\n",
    "    depth_flp = path.join(out_dir, f\"{queue_prefix}_depth.log\")\n",
    "    mark_flp = path.join(out_dir, f\"{queue_prefix}_mark.log\")\n",
    "    drop_flp = path.join(out_dir, f\"{queue_prefix}_drop.log\")\n",
    "\n",
    "    depth_samples = []\n",
    "    with open(depth_flp, \"r\") as fil:\n",
    "        depth_samples = [\n",
    "            parse_queue_line(line) for line in fil if line.strip()[0] != \"#\"\n",
    "        ]\n",
    "    burst_depths = separate_samples_into_bursts(depth_samples, burst_times)\n",
    "\n",
    "    mark_samples = []\n",
    "    with open(mark_flp, \"r\") as fil:\n",
    "        mark_samples = [parse_mark_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    burst_marks = separate_samples_into_bursts(mark_samples, burst_times, bookend=False)\n",
    "\n",
    "    drop_samples = []\n",
    "    with open(drop_flp, \"r\") as fil:\n",
    "        drop_samples = [parse_drop_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "    burst_drops = separate_samples_into_bursts(drop_samples, burst_times, bookend=False)\n",
    "\n",
    "    num_bursts = len(burst_depths)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, (ax, burst) in enumerate(zip(axes, burst_depths)):\n",
    "        # Plot marks and drops on a second y axis\n",
    "\n",
    "        # If there are marks, plot them...\n",
    "        if burst_idx < len(burst_marks) and burst_marks[burst_idx]:\n",
    "            mark_xs, _ = zip(*burst_marks[burst_idx])\n",
    "            mark_ys = [marking_threshold_packets] * len(mark_xs)\n",
    "            ax.plot(mark_xs, mark_ys, \"x\", color=\"orange\", label=\"ECN marks\", alpha=0.8)\n",
    "\n",
    "        # If there are drops, plot them...\n",
    "        if burst_idx < len(burst_drops) and burst_drops[burst_idx]:\n",
    "            drop_xs, _ = zip(*burst_drops[burst_idx])\n",
    "            drop_ys = [capacity_packets] * len(drop_xs)\n",
    "            ax.plot(drop_xs, drop_ys, \"x\", color=\"red\", label=\"Drops\", alpha=0.8)\n",
    "\n",
    "        # Plot depth\n",
    "        xs, ys = zip(*burst)\n",
    "        blue = \"tab:blue\"\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", color=blue, alpha=0.8)\n",
    "\n",
    "        # Draw a line at the marking threshold\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [marking_threshold_packets] * 2,\n",
    "            label=\"Marking threshold\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        # Draw a line at the queue capacity\n",
    "        ax.plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [capacity_packets] * 2,\n",
    "            label=\"Queue capacity\",\n",
    "            color=\"red\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{queue_name} Length: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"queue length (packets)\")\n",
    "        # ax.tick_params(axis='y', labelcolor=blue)\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "graph_queue(\n",
    "    path.join(OUT_DIR, \"log\"),\n",
    "    \"Incast Queue\",\n",
    "    BURST_TIMES,\n",
    "    MARKING_THRESHOLD,\n",
    "    QUEUE_CAPACITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce597b6e-74ef-4963-9935-39603d0e34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_queue(\n",
    "    path.join(OUT_DIR, \"log\"),\n",
    "    \"Uplink Queue\",\n",
    "    BURST_TIMES,\n",
    "    MARKING_THRESHOLD,\n",
    "    QUEUE_CAPACITY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be6075-4fbc-4b8a-88a0-d122b3db0d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_flow_times(flow_times_json):\n",
    "    return [\n",
    "        {times[\"id\"]: (times[\"start\"], times[\"end\"], ip) for ip, times in flows.items()}\n",
    "        for burst, flows in sorted(flow_times_json.items(), key=lambda p: int(p[0]))\n",
    "    ]\n",
    "\n",
    "\n",
    "def graph_active_connections(log_dir, burst_times):\n",
    "    with open(path.join(log_dir, \"flow_times.json\"), \"r\") as fil:\n",
    "        flow_times = json.load(fil)\n",
    "    flow_times = parse_flow_times(flow_times)\n",
    "\n",
    "    num_bursts = len(flow_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        times = flow_times[burst_idx].values()\n",
    "        starts, ends, _ = zip(*times)\n",
    "        serialized = [(start, 1) for start in starts] + [(end, -1) for end in ends]\n",
    "        serialized = sorted(serialized, key=lambda p: p[0])\n",
    "        # earliest_time = serialized[0][0]\n",
    "        # serialized = [(x - earliest_time, y) for x, y in serialized]\n",
    "        active = [serialized[0]]\n",
    "        for time, action in serialized[1:]:\n",
    "            active.append((time, active[-1][1] + action))\n",
    "        xs, ys = zip(*active)\n",
    "\n",
    "        ax.plot(xs, ys, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Active connections over time: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"active connections\")\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    return flow_times\n",
    "\n",
    "\n",
    "FLOW_TIMES = graph_active_connections(path.join(OUT_DIR, \"log\"), BURST_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e9b9c-411e-4461-9869-5d3671dda229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_cdf_of_flow_duration(flow_times, burst_times):\n",
    "    num_bursts = len(flow_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(5, 3 * num_bursts), nrows=num_bursts, ncols=1)\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        times = flow_times[burst_idx].values()\n",
    "        durations = [end - start for start, end, _ in times]\n",
    "\n",
    "        count, bins_count = np.histogram(durations, bins=len(durations))\n",
    "        ax.plot(bins_count[1:], np.cumsum(count / sum(count)), alpha=0.8)\n",
    "\n",
    "        ax.set_title(f\"CDF of flow duration: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax.set_xlabel(\"duration (seconds)\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "graph_cdf_of_flow_duration(FLOW_TIMES, BURST_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491fc08-1963-4a89-a561-3fdc27561b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_cwnd_line(line):\n",
    "    parts = line.strip().split(\" \")\n",
    "    assert len(parts) == 2\n",
    "    time_sec, cwnd_bytes = parts\n",
    "    time_sec = float(time_sec)\n",
    "    cwnd_bytes = int(cwnd_bytes)\n",
    "    return time_sec, cwnd_bytes\n",
    "\n",
    "\n",
    "def parse_cwnds(flp):\n",
    "    with open(flp, \"r\") as fil:\n",
    "        return [parse_cwnd_line(line) for line in fil if line.strip()[0] != \"#\"]\n",
    "\n",
    "\n",
    "def parse_sender(flp):\n",
    "    return int(path.basename(flp).split(\"_\")[0][6:])\n",
    "\n",
    "\n",
    "def graph_sender_cwnd(out_dir, burst_times, flow_times):\n",
    "    cwnd_flps = [\n",
    "        path.join(out_dir, fln)\n",
    "        for fln in os.listdir(out_dir)\n",
    "        if fln.startswith(\"sender\") and fln.endswith(\"_cwnd.log\")\n",
    "    ]\n",
    "\n",
    "    sender_to_cwnds_by_burst = {\n",
    "        parse_sender(flp): separate_samples_into_bursts(\n",
    "            # Read all CWND samples for this sender\n",
    "            parse_cwnds(flp),\n",
    "            burst_times,\n",
    "            # Look up the start and end time for this sender\n",
    "            [burst_flow_times[parse_sender(flp)] for burst_flow_times in flow_times],\n",
    "            filter_on_flow_times=True,\n",
    "            earliest_sec=False,\n",
    "            bookend=True,\n",
    "        )\n",
    "        for flp in cwnd_flps\n",
    "    }\n",
    "\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(10, 3 * num_bursts), nrows=num_bursts, ncols=1\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        ax.set_title(\n",
    "            f\"CWND of active connections: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"time (seconds)\")\n",
    "        ax.set_ylabel(\"CWND (bytes)\")\n",
    "\n",
    "        for sender, bursts in sender_to_cwnds_by_burst.items():\n",
    "            if not bursts[burst_idx]:\n",
    "                continue\n",
    "            xs, ys = zip(*bursts[burst_idx])\n",
    "            ax.plot(xs, ys, label=sender, drawstyle=\"steps-post\", alpha=0.8)\n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    return sender_to_cwnds_by_burst\n",
    "\n",
    "\n",
    "SENDER_TO_CWNDS_BY_BURST = graph_sender_cwnd(\n",
    "    path.join(OUT_DIR, \"log\"), BURST_TIMES, FLOW_TIMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d4e81-9f1e-41a6-bf4f-2f2fb660a178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspired by https://stackoverflow.com/questions/10058227/calculating-mean-of-arrays-with-different-lengths\n",
    "def tolerant_metrics(xs, arrays, interp_delta, percentiles):\n",
    "    # Map x value to index. Used to quickly determine where each array starts\n",
    "    # relative to the overall xs.\n",
    "    xs_map = {\n",
    "        round(x, int(math.log(interp_delta, 10))): idx for idx, x in enumerate(xs)\n",
    "    }\n",
    "\n",
    "    # Create 2d array to fit the largest array\n",
    "    combined_2d = np.ma.empty((len(xs), len(arrays)))\n",
    "    combined_2d.mask = True\n",
    "\n",
    "    for idx, array in enumerate(arrays):\n",
    "        # Look up this array's start position\n",
    "        start_idx = xs_map[round(array[0][0], int(math.log(interp_delta, 10)))]\n",
    "        combined_2d[start_idx : start_idx + len(array), idx] = list(zip(*array))[1]\n",
    "\n",
    "    return (\n",
    "        combined_2d.mean(axis=-1),\n",
    "        combined_2d.std(axis=-1),\n",
    "        combined_2d.min(axis=-1),\n",
    "        combined_2d.max(axis=-1),\n",
    "        np.nanpercentile(\n",
    "            np.ma.filled(np.ma.masked_where(combined_2d < 0, combined_2d), np.nan),\n",
    "            percentiles,\n",
    "            axis=-1,\n",
    "        ),\n",
    "        combined_2d.sum(axis=-1),\n",
    "    )\n",
    "\n",
    "\n",
    "def step_interp(old_xs, old_ys, new_xs):\n",
    "    # Lengths must be nonzero and agree.\n",
    "    assert len(old_xs) > 0\n",
    "    assert len(old_ys) > 0\n",
    "    assert len(new_xs) > 0\n",
    "    assert len(old_xs) == len(old_ys)\n",
    "    # xs must be strictly non-decreasing.\n",
    "    assert (np.diff(old_xs) >= 0).all(), np.diff(old_xs)\n",
    "    assert (np.diff(new_xs) >= 0).all()\n",
    "    # This is strictly interpolation, not extrapolation.\n",
    "    assert new_xs[0] >= old_xs[0]\n",
    "    assert new_xs[-1] <= old_xs[-1]\n",
    "\n",
    "    new_ys = np.empty(len(new_xs))\n",
    "    # Points to the next value in xs and ys that is past the current x we are interpolating.\n",
    "    old_idx = 0\n",
    "    for new_idx, new_x in enumerate(new_xs):\n",
    "        # Move old_idx forward until it is at a position where the next element\n",
    "        # in old_xs is strictly greater than new_x.\n",
    "        #\n",
    "        # old_idx will never grow larger than len(old_xs) - 2\n",
    "        while old_idx < len(old_xs) - 2 and new_x >= old_xs[old_idx + 1]:\n",
    "            old_idx += 1\n",
    "\n",
    "        # If old_idx is immediately before the last element in old_xs, then\n",
    "        # check manually if we need to advance old_idx to the last element in\n",
    "        # old_xs.\n",
    "        if old_idx == len(old_xs) - 2:\n",
    "            if new_x >= old_xs[len(old_xs) - 1]:\n",
    "                old_idx += 1\n",
    "\n",
    "        new_ys[new_idx] = old_ys[old_idx]\n",
    "\n",
    "    assert len(new_xs) == len(new_ys)\n",
    "    return new_ys\n",
    "\n",
    "\n",
    "def interpolate_flows_for_burst(\n",
    "    sender_to_cwnds_by_burst, sender_to_cwnds_by_burst_interp, burst_idx, interp_delta\n",
    "):\n",
    "    # Interpolate each flow at uniform intervals.\n",
    "    for sender, bursts in sender_to_cwnds_by_burst.items():\n",
    "        if bursts[burst_idx]:\n",
    "            start_x = bursts[burst_idx][0][0]\n",
    "            end_x = bursts[burst_idx][-1][0]\n",
    "            new_xs = np.array(\n",
    "                [\n",
    "                    x / interp_delta\n",
    "                    for x in range(\n",
    "                        math.ceil(start_x * interp_delta),\n",
    "                        math.floor(end_x * interp_delta) + 1,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            new_ys = step_interp(*zip(*bursts[burst_idx]), new_xs)\n",
    "        else:\n",
    "            new_xs = np.array([])\n",
    "            new_ys = np.array([])\n",
    "        sender_to_cwnds_by_burst_interp[sender].append(list(zip(new_xs, new_ys)))\n",
    "\n",
    "\n",
    "def calculate_aggregate_metrics(valid, interp_delta, percentiles):\n",
    "    # Determine the overall x-axis range for this burst, across all valid senders.\n",
    "    start_x = min(samples[0][0] for samples in valid)\n",
    "    end_x = max(samples[-1][0] for samples in valid)\n",
    "    xs = np.array(\n",
    "        [\n",
    "            x / interp_delta\n",
    "            for x in range(\n",
    "                math.floor(start_x * interp_delta), math.ceil(end_x * interp_delta) + 1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate and verify metrics.\n",
    "    avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys = tolerant_metrics(\n",
    "        xs, valid, interp_delta, percentiles\n",
    "    )\n",
    "    assert len(xs) == len(avg_ys)\n",
    "    assert len(xs) == len(stdev_ys)\n",
    "    assert len(xs) == len(min_ys)\n",
    "    assert len(xs) == len(max_ys)\n",
    "    assert len(xs) == percentiles_ys.shape[1]\n",
    "    assert len(xs) == len(sum_ys)\n",
    "\n",
    "    return xs, avg_ys, stdev_ys, min_ys, max_ys, percentiles_ys, sum_ys\n",
    "\n",
    "\n",
    "def graph_aggregate_cwnd_per_burst_helper(\n",
    "    ax,\n",
    "    sender_to_cwnds_by_burst,\n",
    "    sender_to_cwnds_by_burst_interp,\n",
    "    burst_idx,\n",
    "    burst_times,\n",
    "    interp_delta,\n",
    "    percentiles,\n",
    "):\n",
    "    interpolate_flows_for_burst(\n",
    "        sender_to_cwnds_by_burst,\n",
    "        sender_to_cwnds_by_burst_interp,\n",
    "        burst_idx,\n",
    "        interp_delta,\n",
    "    )\n",
    "\n",
    "    # Throw away senders that do not have any samples for this burst.\n",
    "    valid = [\n",
    "        bursts[burst_idx]\n",
    "        for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "        if bursts[burst_idx]\n",
    "    ]\n",
    "    print(\n",
    "        f\"Burst {burst_idx} has \"\n",
    "        f\"{len(valid)}/{len(sender_to_cwnds_by_burst_interp)} \"\n",
    "        \"senders with at least one CWND sample.\"\n",
    "    )\n",
    "\n",
    "    (\n",
    "        xs,\n",
    "        avg_ys,\n",
    "        stdev_ys,\n",
    "        min_ys,\n",
    "        max_ys,\n",
    "        percentiles_ys,\n",
    "        _,\n",
    "    ) = calculate_aggregate_metrics(valid, interp_delta, percentiles)\n",
    "\n",
    "    # Left graph\n",
    "    ax[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "    ax[0].fill_between(\n",
    "        xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "    )\n",
    "    ax[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    ax[0].set_title(\n",
    "        f\"CWND of active connections: Burst {burst_idx + 1} of {len(burst_times)}\"\n",
    "    )\n",
    "    ax[0].set_xlabel(\"time (seconds)\")\n",
    "    ax[0].set_ylabel(\"CWND (bytes)\")\n",
    "    ax[0].set_ylim(bottom=0)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Right graph\n",
    "    ax[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    for idx in range(1, percentiles_ys.shape[0]):\n",
    "        ax[1].fill_between(\n",
    "            xs,\n",
    "            percentiles_ys[idx - 1],\n",
    "            percentiles_ys[idx],\n",
    "            alpha=0.5,\n",
    "            label=f\"p{percentiles[idx]}\",\n",
    "        )\n",
    "    ax[1].set_title(\n",
    "        f\"CWND of active connections: Burst {burst_idx + 1} of {len(burst_times)}\"\n",
    "    )\n",
    "    ax[1].set_xlabel(\"time (seconds)\")\n",
    "    ax[1].set_ylabel(\"CWND (bytes)\")\n",
    "    ax[1].set_ylim(bottom=0)\n",
    "    ax[1].legend()\n",
    "\n",
    "\n",
    "def graph_aggregate_cwnd_per_burst(\n",
    "    sender_to_cwnds_by_burst, burst_times, interp_delta, percentiles\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(15, 3 * num_bursts), nrows=num_bursts, ncols=2\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Calculate aggregate metrics, graph them, and store interpolated flows in\n",
    "    # this dict.\n",
    "    sender_to_cwnds_by_burst_interp = collections.defaultdict(list)\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        graph_aggregate_cwnd_per_burst_helper(\n",
    "            ax,\n",
    "            sender_to_cwnds_by_burst,\n",
    "            sender_to_cwnds_by_burst_interp,\n",
    "            burst_idx,\n",
    "            burst_times,\n",
    "            interp_delta,\n",
    "            percentiles,\n",
    "        )\n",
    "\n",
    "    for sender, bursts_interp in sender_to_cwnds_by_burst_interp.items():\n",
    "        assert len(bursts_interp) == num_bursts\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "    return sender_to_cwnds_by_burst_interp\n",
    "\n",
    "\n",
    "INTERP_DELTA = 1e5\n",
    "PERCENTILES = [0, 25, 50, 75, 95, 100]\n",
    "SENDER_TO_CWNDS_BY_BURST_INTERP = graph_aggregate_cwnd_per_burst(\n",
    "    SENDER_TO_CWNDS_BY_BURST, BURST_TIMES, INTERP_DELTA, PERCENTILES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc479fb-5120-48c9-a132-6e3f6f4c3ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_aggregate_cwnd_across_bursts(\n",
    "    sender_to_cwnds_by_burst_interp, num_bursts, interp_delta, percentiles\n",
    "):\n",
    "    # We always ignore the first burst, since it is different than the others\n",
    "    # due to slow start.\n",
    "    if num_bursts == 1:\n",
    "        print(\n",
    "            \"No results because we ignore the frst burst, but there is only one burst.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Flatten all senders and bursts.\n",
    "    flattened_flows = []\n",
    "    # Throw away the first burst, because it always looks different.\n",
    "    for burst_idx in range(1, num_bursts):\n",
    "        # Find the earliest start time for a flow in this burst.\n",
    "        start_x = min(\n",
    "            bursts[burst_idx][0][0]\n",
    "            for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "        )\n",
    "        for bursts in sender_to_cwnds_by_burst_interp.values():\n",
    "            # Throw away bursts with no samples.\n",
    "            if bursts[burst_idx]:\n",
    "                flattened_flows.append(\n",
    "                    [\n",
    "                        # Make all bursts start at time 0.\n",
    "                        (sample[0] - start_x, *sample[1:])\n",
    "                        for sample in bursts[burst_idx]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    (\n",
    "        xs,\n",
    "        avg_ys,\n",
    "        stdev_ys,\n",
    "        min_ys,\n",
    "        max_ys,\n",
    "        percentiles_ys,\n",
    "        _,\n",
    "    ) = calculate_aggregate_metrics(flattened_flows, interp_delta, percentiles)\n",
    "\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(figsize=(15, 3), nrows=1, ncols=2)\n",
    "\n",
    "    # Left graph\n",
    "    axes[0].fill_between(xs, min_ys, max_ys, alpha=0.25, label=\"min/max\")\n",
    "    axes[0].fill_between(\n",
    "        xs, avg_ys - stdev_ys, avg_ys + stdev_ys, alpha=0.5, label=\"avg +/- stdev\"\n",
    "    )\n",
    "    axes[0].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    axes[0].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[0].set_xlabel(\"time (seconds)\")\n",
    "    axes[0].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[0].set_ylim(bottom=0)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Right graph\n",
    "    axes[1].plot(xs, avg_ys, label=\"avg\", alpha=0.8)\n",
    "    for idx in range(1, percentiles_ys.shape[0]):\n",
    "        axes[1].fill_between(\n",
    "            xs,\n",
    "            percentiles_ys[idx - 1],\n",
    "            percentiles_ys[idx],\n",
    "            alpha=0.5,\n",
    "            label=f\"p{percentiles[idx]}\",\n",
    "        )\n",
    "    axes[1].set_title(\"CWND of active connections across all bursts\")\n",
    "    axes[1].set_xlabel(\"time (seconds)\")\n",
    "    axes[1].set_ylabel(\"CWND (bytes)\")\n",
    "    axes[1].set_ylim(bottom=0)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "graph_aggregate_cwnd_across_bursts(\n",
    "    SENDER_TO_CWNDS_BY_BURST_INTERP, len(BURST_TIMES), INTERP_DELTA, PERCENTILES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3af6be-9dd4-4905-a35a-70ce61eecba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_total_cwnd(\n",
    "    sender_to_cwnds_by_burst_interp, burst_times, bdp_bytes, interp_delta\n",
    "):\n",
    "    num_bursts = len(burst_times)\n",
    "    with plt.ioff():\n",
    "        fig, axes = plt.subplots(\n",
    "            figsize=(15, 3 * num_bursts), nrows=num_bursts, ncols=2\n",
    "        )\n",
    "    if num_bursts == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for burst_idx, ax in enumerate(axes):\n",
    "        valid = [\n",
    "            bursts[burst_idx]\n",
    "            for bursts in sender_to_cwnds_by_burst_interp.values()\n",
    "            if bursts[burst_idx]\n",
    "        ]\n",
    "        xs, _, _, _, _, _, sum_ys = calculate_aggregate_metrics(\n",
    "            valid, interp_delta, percentiles=[]\n",
    "        )\n",
    "\n",
    "        ax[0].plot(xs, sum_ys, label=\"Total CWND of active connections\", alpha=0.8)\n",
    "\n",
    "        # Draw a line at the BDP\n",
    "        ax[0].plot(\n",
    "            [xs[0], xs[-1]],\n",
    "            [bdp_bytes, bdp_bytes],\n",
    "            label=\"BDP\",\n",
    "            color=\"orange\",\n",
    "            linestyle=\"dashed\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax[0].set_title(f\"Total CWND in bytes: Burst {burst_idx + 1} of {num_bursts}\")\n",
    "        ax[0].set_xlabel(\"time (seconds)\")\n",
    "        ax[0].set_ylabel(\"bytes\")\n",
    "        ax[0].set_ylim(bottom=0)\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(\n",
    "            xs,\n",
    "            [y / bdp_bytes for y in sum_ys],\n",
    "            label=\"Total CWND as a multiple of BDP\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        ax[1].set_title(\n",
    "            f\"Total CWND in multiples of BDP: Burst {burst_idx + 1} of {num_bursts}\"\n",
    "        )\n",
    "        ax[1].set_xlabel(\"time (seconds)\")\n",
    "        ax[1].set_ylabel(\"multiples of the BDP\")\n",
    "        ax[1].set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Change the toolbar position\n",
    "    fig.canvas.toolbar_position = \"left\"\n",
    "    # If true then scrolling while the mouse is over the canvas will not move the entire notebook\n",
    "    fig.canvas.capture_scroll = True\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "BDP_BYTES = 12.5e9 / 8 * 6 * 5e-6\n",
    "graph_total_cwnd(SENDER_TO_CWNDS_BY_BURST_INTERP, BURST_TIMES, BDP_BYTES, INTERP_DELTA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incast-analysis-venv",
   "language": "python",
   "name": "incast-analysis-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
